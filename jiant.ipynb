{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5qfgMCwATNo12IL9yUGSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laslil7437/tiny-blimp-eval/blob/main/jiant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Jiant"
      ],
      "metadata": {
        "id": "fs7cIVGGq1DL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can largely ignore this section, adapted from https://github.com/alexwarstadt/blimp/issues/5\n",
        "\n",
        "There are no errors here that I know of, so jump to \"Notes\" section."
      ],
      "metadata": {
        "id": "dSKf-5sFUa5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -bf -p /usr/local"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYf3UXjLq0y2",
        "outputId": "6c576e51-d105-45ec-fad6-21c16c653018",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-20 15:46:52--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 148337011 (141M) [application/octet-stream]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 141.46M   147MB/s    in 1.0s    \n",
            "\n",
            "2024-11-20 15:46:54 (147 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [148337011/148337011]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/laslil7437/tiny-blimp-eval.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OLbIleksAXG",
        "outputId": "c8843a7b-08ee-4a1e-b4f8-0df1963cf591",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tiny-blimp-eval'...\n",
            "remote: Enumerating objects: 334, done.\u001b[K\n",
            "remote: Counting objects: 100% (334/334), done.\u001b[K\n",
            "remote: Compressing objects: 100% (278/278), done.\u001b[K\n",
            "remote: Total 334 (delta 84), reused 269 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (334/334), 1.33 MiB | 4.48 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env update -f tiny-blimp-eval/jiant/environment.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31HdbMivsFAq",
        "outputId": "27a52d1c-7e21-4b6a-ee08-10df97e768ad",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/argparse.py:2006: FutureWarning: `remote_definition` is deprecated and will be removed in 25.9. Use `conda env create --file=URL` instead.\n",
            "  action(self, namespace, argument_values, option_string)\n",
            "Channels:\n",
            " - pytorch\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bdone\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "pytorch-1.10.2       | 1.21 GB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-0.24.2  | 5.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2022.1. | 4.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-1.19.2    | 4.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bokeh-1.2.0          | 3.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.6.15        | 1.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ipython-7.16.1       | 999 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran4-7.5.0   | 995 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 950 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jedi-0.17.2          | 919 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   0% 5.6893042969979495e-05/1 [00:00<31:18, 1878.14s/it]\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :   0% 0.000962067985804917/1 [00:00<01:51, 112.07s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   0% 1.2630802545127682e-05/1 [00:00<2:35:46, 9346.47s/it]\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :   0% 0.0005145128809103662/1 [00:00<04:01, 242.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   0% 0.0023041682402841694/1 [00:00<01:16, 76.49s/it]   \u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :   7% 0.07119303094956386/1 [00:00<00:02,  2.48s/it]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   0% 0.001111510623971236/1 [00:00<02:45, 165.41s/it]     \n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :   3% 0.02881272133098051/1 [00:00<00:06,  6.53s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   1% 0.008164151666192058/1 [00:00<00:29, 29.89s/it] \u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  17% 0.1669187955371531/1 [00:00<00:01,  1.54s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   0% 0.004016595209350603/1 [00:00<01:02, 62.53s/it] \n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  15% 0.14817970970218547/1 [00:00<00:01,  1.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   1% 0.014337046828434832/1 [00:00<00:22, 22.59s/it]\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  28% 0.27803764789762103/1 [00:00<00:00,  1.22s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   1% 0.007186926648177651/1 [00:00<00:45, 45.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  27% 0.26857572383521117/1 [00:00<00:00,  1.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   2% 0.0210788724203774/1 [00:00<00:18, 19.05s/it]  \u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  40% 0.39829614612323566/1 [00:00<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   1% 0.01030673487682419/1 [00:00<00:39, 39.75s/it] \n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  39% 0.39257332813460943/1 [00:00<00:00,  1.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   3% 0.027422446711530116/1 [00:00<00:17, 17.82s/it]\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  50% 0.4964270806753372/1 [00:00<00:00,  1.04s/it] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   1% 0.01313603464693279/1 [00:00<00:37, 38.35s/it]\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  50% 0.504222623292159/1 [00:00<00:00,  1.02it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   3% 0.03416427230347269/1 [00:00<00:16, 16.73s/it] \u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  13% 0.13102482835093515/1 [00:00<00:03,  4.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   2% 0.015775872378864474/1 [00:00<00:38, 38.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  61% 0.6086687381169632/1 [00:00<00:00,  1.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   4% 0.04076386528799031/1 [00:00<00:16, 16.87s/it]\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  16% 0.15677798426818793/1 [00:00<00:03,  4.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   2% 0.018807264989695118/1 [00:00<00:36, 37.56s/it]\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  72% 0.7157785814388583/1 [00:00<00:00,  1.02s/it]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   5% 0.04690831392874809/1 [00:00<00:15, 16.69s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   2% 0.02180076519289038/1 [00:00<00:36, 37.07s/it] \n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  84% 0.8360834314793452/1 [00:00<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  86% 0.8562405073663761/1 [00:00<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   5% 0.05310965561247586/1 [00:01<00:15, 16.67s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   2% 0.02469321897572462/1 [00:01<00:35, 36.58s/it]\n",
            "\n",
            "\n",
            "\n",
            "torchvision-0.11.3   | 30.4 MB   | :  95% 0.9549359069696397/1 [00:01<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.6.13        | 32.5 MB   | :  96% 0.9615869518120146/1 [00:01<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   6% 0.05959546251105352/1 [00:01<00:15, 16.27s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   3% 0.027434103128017324/1 [00:01<00:35, 36.87s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   7% 0.0679587398276405/1 [00:01<00:13, 14.69s/it] \u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   3% 0.031021251050833587/1 [00:01<00:32, 33.69s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   8% 0.07723230583174716/1 [00:01<00:12, 13.26s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   3% 0.03477259940673651/1 [00:01<00:30, 31.36s/it] \n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :   9% 0.08559558314833415/1 [00:01<00:11, 13.01s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   4% 0.037993454055744065/1 [00:01<00:30, 31.57s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :   4% 0.04141640154547367/1 [00:01<00:30, 31.89s/it] \n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  38% 0.3797460973412448/1 [00:01<00:02,  3.39s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   4% 0.04456147137921046/1 [00:01<00:32, 34.24s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  41% 0.40967849347313945/1 [00:01<00:02,  3.66s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   5% 0.048527543378380555/1 [00:01<00:29, 31.17s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  44% 0.4374647932785964/1 [00:01<00:02,  3.68s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | :   0% 0.0010823803488774003/1 [00:01<27:50, 1672.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   5% 0.0522915225368286/1 [00:01<00:28, 29.77s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :   0% 0.0015713236502815128/1 [00:01<20:03, 1205.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  47% 0.4650251882075862/1 [00:01<00:02,  3.81s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | :   5% 0.050871876397237815/1 [00:01<00:25, 27.08s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :  10% 0.0974220663174538/1 [00:01<00:13, 14.72s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | :  23% 0.22621749291537668/1 [00:02<00:03,  5.02s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   6% 0.05568920842146795/1 [00:02<00:34, 36.23s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  49% 0.4915690111924739/1 [00:02<00:02,  4.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :  36% 0.36454708686531095/1 [00:02<00:02,  3.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | :  33% 0.3290436260587297/1 [00:02<00:02,  3.36s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   6% 0.05868270862466321/1 [00:02<00:34, 36.73s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :  69% 0.6929537297741472/1 [00:02<00:00,  1.55s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  13% 0.12977303101452323/1 [00:02<00:16, 18.95s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   6% 0.061549900802407194/1 [00:02<00:35, 37.36s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | :  96% 0.9616500739722859/1 [00:02<00:00,  1.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  54% 0.5385572254976368/1 [00:02<00:02,  4.75s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  14% 0.1356330144404311/1 [00:02<00:16, 18.90s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   6% 0.06432867736233529/1 [00:02<00:36, 38.77s/it] \n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  56% 0.5603570460767149/1 [00:02<00:02,  4.73s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   7% 0.06762531682661362/1 [00:02<00:33, 36.36s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  59% 0.5882562983204054/1 [00:02<00:01,  4.45s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   7% 0.07044198579417708/1 [00:02<00:34, 36.92s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  62% 0.6162685030023295/1 [00:02<00:01,  4.26s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  15% 0.15312762515369982/1 [00:02<00:15, 17.95s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    | :   0% 0.0019163444980128336/1 [00:02<23:24, 1406.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  64% 0.6401014674696116/1 [00:02<00:01,  4.31s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :   7% 0.07319550074901492/1 [00:02<00:38, 41.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    | :  34% 0.34494200964231003/1 [00:02<00:03,  5.78s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  16% 0.16487603852700058/1 [00:02<00:14, 17.81s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   8% 0.07569639965295019/1 [00:02<00:39, 42.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    | :  68% 0.6764696077985303/1 [00:02<00:00,  2.61s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-0.24.2  | 5.2 MB    | :   0% 0.0029917185418074587/1 [00:02<16:16, 978.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   8% 0.07812151374161472/1 [00:03<00:42, 45.57s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    | :  99% 0.9850010719785964/1 [00:03<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  17% 0.17056534282399852/1 [00:03<00:17, 21.02s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-0.24.2  | 5.2 MB    | :  44% 0.4397826256456965/1 [00:03<00:02,  4.91s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   8% 0.08072345906591101/1 [00:03<00:40, 43.51s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  18% 0.17582794929872161/1 [00:03<00:16, 20.47s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   8% 0.08307278833930476/1 [00:03<00:44, 48.16s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  18% 0.1809198766445348/1 [00:03<00:19, 23.96s/it] \u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   9% 0.08530844038979236/1 [00:03<00:44, 48.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2022.1. | 4.5 MB    | :   0% 0.003461395531411045/1 [00:03<16:11, 975.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  19% 0.1856135526895581/1 [00:03<00:19, 23.60s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-1.19.2    | 4.1 MB    | :   0% 0.0037940777281107027/1 [00:03<14:47, 891.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   9% 0.08740515361228356/1 [00:03<00:45, 49.96s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2022.1. | 4.5 MB    | :  53% 0.5295935163058898/1 [00:03<00:02,  4.66s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-1.19.2    | 4.1 MB    | :  70% 0.70190437970048/1 [00:03<00:01,  3.53s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  19% 0.19007965656270148/1 [00:03<00:19, 23.80s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   9% 0.08943871282204911/1 [00:03<00:45, 49.83s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  19% 0.19454576043584487/1 [00:03<00:19, 23.67s/it]\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   9% 0.09172488808271723/1 [00:03<00:43, 48.05s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  20% 0.19904031083047327/1 [00:03<00:18, 23.48s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 3.7 MB    | :   0% 0.004187193943698291/1 [00:03<14:43, 887.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bokeh-1.2.0          | 3.5 MB    | :   0% 0.004462893346273835/1 [00:03<13:58, 842.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :   9% 0.09383423210775355/1 [00:03<00:46, 51.52s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 3.7 MB    | :  65% 0.6532022552169334/1 [00:03<00:01,  4.15s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  20% 0.20339262861767668/1 [00:03<00:20, 25.21s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :  10% 0.09627197699896319/1 [00:03<00:43, 48.16s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  86% 0.8567442440015889/1 [00:03<00:00,  5.82s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :  10% 0.09920232318943281/1 [00:04<00:39, 43.61s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  88% 0.8788829218953675/1 [00:04<00:00,  5.46s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  21% 0.2128368737506933/1 [00:04<00:18, 23.28s/it] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | :   1% 0.008513680919876618/1 [00:04<07:49, 473.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :  10% 0.10153902166028143/1 [00:04<00:40, 44.64s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  90% 0.9047490302508538/1 [00:04<00:00,  4.98s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  22% 0.21972093195006082/1 [00:04<00:16, 20.53s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran4-7.5.0   | 995 KB    | :   2% 0.01607593682266723/1 [00:04<04:16, 260.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :  10% 0.10403992056421672/1 [00:04<00:38, 43.45s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  93% 0.9253063740093627/1 [00:04<00:00,  5.14s/it]\u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  23% 0.22600761319824353/1 [00:04<00:14, 19.07s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jedi-0.17.2          | 919 KB    | :   2% 0.017405863430263936/1 [00:04<04:02, 246.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :  11% 0.10651555786306174/1 [00:04<00:38, 43.09s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  95% 0.9462025750825722/1 [00:04<00:00,  5.05s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :  11% 0.1090543491746324/1 [00:04<00:37, 42.35s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | :  98% 0.9761349712144668/1 [00:04<00:00,  4.48s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :  11% 0.11189627974728614/1 [00:04<00:36, 40.71s/it]\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | : 100% 0.9987254588611798/1 [00:04<00:00,  4.48s/it]\u001b[A\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :  12% 0.11534448884210599/1 [00:04<00:32, 37.26s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  12% 0.11833798904530125/1 [00:04<00:36, 41.33s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  12% 0.12087678035687191/1 [00:04<00:36, 41.50s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  12% 0.1235166180888036/1 [00:05<00:35, 40.66s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  13% 0.1260175169927389/1 [00:05<00:35, 40.88s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  13% 0.12897312478829875/1 [00:05<00:33, 38.63s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  13% 0.1315877009151402/1 [00:05<00:33, 39.00s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  13% 0.13454330871070005/1 [00:05<00:33, 38.72s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  14% 0.1372841928629928/1 [00:05<00:33, 38.29s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  14% 0.1408081867730834/1 [00:05<00:29, 34.84s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  14% 0.14466058154934733/1 [00:05<00:27, 31.74s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  15% 0.14783091298817438/1 [00:05<00:29, 34.58s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  15% 0.15110229084736246/1 [00:05<00:28, 33.50s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  15% 0.1544115611141859/1 [00:06<00:27, 32.60s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  16% 0.1577334621835545/1 [00:06<00:27, 32.61s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  16% 0.16137113331655126/1 [00:06<00:26, 31.29s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  17% 0.16533720531572135/1 [00:06<00:24, 29.86s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  17% 0.16911381527671454/1 [00:06<00:23, 28.81s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  17% 0.17259991677916978/1 [00:06<00:23, 28.96s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  18% 0.17607338747907988/1 [00:06<00:24, 29.14s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  18% 0.17972368941462177/1 [00:06<00:23, 28.85s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  18% 0.1831971601145319/1 [00:06<00:24, 29.55s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  19% 0.18673378482716765/1 [00:06<00:23, 29.30s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  19% 0.19130613534850388/1 [00:07<00:21, 26.89s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  20% 0.19514589932222268/1 [00:07<00:21, 26.64s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  20% 0.19890987848067074/1 [00:07<00:22, 28.39s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  20% 0.20247176479839674/1 [00:07<00:22, 28.59s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  21% 0.2064252059950217/1 [00:07<00:21, 27.61s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  21% 0.2111238645418092/1 [00:07<00:20, 25.42s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  22% 0.2156330610504198/1 [00:07<00:19, 24.47s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  22% 0.22034435039975242/1 [00:07<00:18, 23.55s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  23% 0.22528299419489733/1 [00:07<00:17, 22.53s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  23% 0.22974166749332742/1 [00:08<00:17, 22.72s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  23% 0.2348066193139236/1 [00:08<00:16, 21.77s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  24% 0.23966947829379776/1 [00:08<00:16, 21.41s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  24% 0.24435550603804013/1 [00:08<00:16, 21.76s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  25% 0.24896574896701174/1 [00:08<00:18, 24.24s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  25% 0.2531844370170844/1 [00:08<00:19, 26.05s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  26% 0.25841358927076724/1 [00:08<00:17, 23.76s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  26% 0.2627333237412009/1 [00:08<00:17, 24.06s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  27% 0.2669646425938187/1 [00:08<00:17, 23.96s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  27% 0.2711959614464365/1 [00:09<00:17, 24.05s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  28% 0.27557884992959575/1 [00:09<00:17, 23.69s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  28% 0.2798354303873038/1 [00:09<00:17, 24.60s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  28% 0.28394044121447026/1 [00:09<00:17, 24.66s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  29% 0.28802019043654653/1 [00:09<00:18, 25.98s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  29% 0.29191047762044586/1 [00:09<00:19, 26.96s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  30% 0.2957502415941647/1 [00:09<00:19, 27.05s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  30% 0.29947632834497734/1 [00:09<00:18, 27.01s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  30% 0.30320241509579/1 [00:09<00:19, 27.27s/it]   \n",
            "pytorch-1.10.2       | 1.21 GB   | :  31% 0.30687797863642213/1 [00:09<00:19, 28.10s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  31% 0.31066721939996045/1 [00:10<00:19, 28.11s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  32% 0.31744996036669404/1 [00:10<00:22, 32.38s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  32% 0.3207718614360626/1 [00:10<00:21, 32.35s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  32% 0.3239169312697994/1 [00:10<00:21, 32.22s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  33% 0.32754197160025106/1 [00:10<00:20, 31.09s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  33% 0.33086387266961964/1 [00:10<00:21, 31.50s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  34% 0.33520886874514355/1 [00:10<00:19, 29.07s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  34% 0.33908652512649773/1 [00:10<00:18, 28.05s/it]\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  75% 0.7517562232838241/1 [00:10<00:03, 13.59s/it]\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | :  76% 0.7622814362332703/1 [00:11<00:02, 12.13s/it]\u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | :  34% 0.342673673049314/1 [00:11<00:25, 39.04s/it]  \n",
            "pytorch-1.10.2       | 1.21 GB   | :  35% 0.3466523758510292/1 [00:11<00:22, 35.03s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  35% 0.3502395237738455/1 [00:11<00:21, 33.37s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  36% 0.35803272894418925/1 [00:11<00:18, 29.48s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  36% 0.36160724606446043/1 [00:12<00:45, 71.62s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  36% 0.36490388552873876/1 [00:12<00:38, 60.34s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  37% 0.3690720503686309/1 [00:12<00:31, 49.65s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  37% 0.37244447464818/1 [00:12<00:27, 44.24s/it]  \n",
            "pytorch-1.10.2       | 1.21 GB   | :  38% 0.376208453806628/1 [00:12<00:24, 38.94s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  38% 0.3811344667992278/1 [00:12<00:19, 32.16s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  39% 0.38645203467072653/1 [00:12<00:16, 27.69s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  39% 0.39064546111570897/1 [00:12<00:16, 26.65s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  39% 0.3948262567581462/1 [00:13<00:15, 26.06s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  40% 0.3989691599929481/1 [00:13<00:16, 27.91s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  40% 0.40418568144408584/1 [00:13<00:15, 25.39s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  41% 0.4083285846788877/1 [00:13<00:16, 28.20s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  41% 0.41250938032132495/1 [00:13<00:15, 27.08s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  42% 0.41728382368338324/1 [00:13<00:14, 25.12s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  42% 0.4222982522937989/1 [00:13<00:13, 23.45s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  43% 0.4271358496685828/1 [00:13<00:13, 22.72s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  43% 0.4316450461771934/1 [00:13<00:12, 22.71s/it]\n",
            "pytorch-1.10.2       | 1.21 GB   | :  44% 0.436646843985064/1 [00:14<00:12, 22.21s/it] \n",
            "pytorch-1.10.2       | 1.21 GB   | :  81% 0.8053273394747958/1 [00:23<00:06, 33.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | :  96% 0.9551539192651004/1 [00:26<00:00, 17.06s/it]\n",
            "\n",
            "\n",
            "pytorch-1.10.2       | 1.21 GB   | : 100% 0.9987680804534264/1 [00:27<00:00, 18.65s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:28<00:00,  1.07s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | : 100% 1.0/1 [00:29<00:00, 47.60s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.5.2          | 14.4 MB   | : 100% 1.0/1 [00:29<00:00, 47.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-0.24.2  | 5.2 MB    | : 100% 1.0/1 [00:30<00:00, 33.33s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-0.24.2  | 5.2 MB    | : 100% 1.0/1 [00:30<00:00, 33.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-1.1.5         | 8.2 MB    | : 100% 1.0/1 [00:31<00:00,  1.62s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-1.19.2    | 4.1 MB    | : 100% 1.0/1 [00:31<00:00,  3.53s/it]             \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2022.1. | 4.5 MB    | : 100% 1.0/1 [00:31<00:00, 35.35s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-openmp-2022.1. | 4.5 MB    | : 100% 1.0/1 [00:31<00:00, 35.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:31<00:00,  4.15s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:31<00:00, 30.76s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:31<00:00, 30.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:32<00:00, 31.46s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:32<00:00, 31.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ipython-7.16.1       | 999 KB    | : 100% 1.0/1 [00:33<00:00, 32.04s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ipython-7.16.1       | 999 KB    | : 100% 1.0/1 [00:33<00:00, 32.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran4-7.5.0   | 995 KB    | : 100% 1.0/1 [00:33<00:00, 32.13s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran4-7.5.0   | 995 KB    | : 100% 1.0/1 [00:33<00:00, 32.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bokeh-1.2.0          | 3.5 MB    | : 100% 1.0/1 [00:33<00:00,  3.18s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 950 KB    | : 100% 1.0/1 [00:33<00:00, 32.23s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 950 KB    | : 100% 1.0/1 [00:33<00:00, 32.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jedi-0.17.2          | 919 KB    | : 100% 1.0/1 [00:35<00:00, 33.94s/it]                  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jedi-0.17.2          | 919 KB    | : 100% 1.0/1 [00:35<00:00, 33.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "mkl-2020.2           | 138.3 MB  | : 100% 1.0/1 [00:46<00:00,  4.48s/it]               \u001b[A\u001b[A\n",
            "cudatoolkit-11.3.1   | 549.3 MB  | : 100% 1.0/1 [00:56<00:00, 1105.61s/it]             \u001b[A\n",
            "pytorch-1.10.2       | 1.21 GB   | : 100% 1.0/1 [04:13<00:00, 18.65s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                          \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \n",
            "\n",
            "    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\n",
            "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
            "\n",
            "    For example:\n",
            "\n",
            "        $ conda install scikit-learn-intelex\n",
            "        $ python -m sklearnex my_application.py\n",
            "\n",
            "    \n",
            "\n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Installing pip dependencies: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/jiant/bin/python', '-m', 'pip', 'install', '-U', '-r', '/root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting allennlp==0.8.4\n",
            "  Downloading allennlp-0.8.4-py3-none-any.whl (5.7 MB)\n",
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "Collecting tensorboardX==1.2\n",
            "  Downloading tensorboardX-1.2-py2.py3-none-any.whl (44 kB)\n",
            "Collecting sendgrid==5.4.1\n",
            "  Downloading sendgrid-5.4.1-py2.py3-none-any.whl (49 kB)\n",
            "Collecting pyhocon==0.3.35\n",
            "  Downloading pyhocon-0.3.35.tar.gz (94 kB)\n",
            "Collecting nose2\n",
            "  Downloading nose2-0.13.0-py3-none-any.whl (205 kB)\n",
            "Collecting pre-commit==1.15.2\n",
            "  Downloading pre_commit-1.15.2-py2.py3-none-any.whl (152 kB)\n",
            "Collecting python-Levenshtein==0.12.0\n",
            "  Downloading python-Levenshtein-0.12.0.tar.gz (48 kB)\n",
            "Collecting google-cloud-logging==1.11.0\n",
            "  Downloading google_cloud_logging-1.11.0-py2.py3-none-any.whl (132 kB)\n",
            "Collecting spacy==2.1\n",
            "  Downloading spacy-2.1.0-cp36-cp36m-manylinux1_x86_64.whl (27.7 MB)\n",
            "Collecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "  Downloading pytorch_transformers-1.1.0-py3-none-any.whl (158 kB)\n",
            "Collecting editdistance\n",
            "  Downloading editdistance-0.6.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "Collecting overrides\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/jiant/lib/python3.6/site-packages (from allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (1.19.2)\n",
            "Collecting matplotlib>=2.2.3\n",
            "  Downloading matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "Collecting sqlparse>=0.2.4\n",
            "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting h5py\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "Collecting conllu==0.11\n",
            "  Downloading conllu-0.11-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
            "Collecting flask>=1.0.2\n",
            "  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/envs/jiant/lib/python3.6/site-packages (from allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (1.10.2)\n",
            "Collecting gevent>=1.3.6\n",
            "  Downloading gevent-22.10.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/envs/jiant/lib/python3.6/site-packages (from allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (2017.3)\n",
            "Collecting numpydoc>=0.8.0\n",
            "  Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
            "Collecting flaky\n",
            "  Downloading flaky-3.8.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting tqdm>=4.19\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "Collecting requests>=2.18\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting responses>=0.7\n",
            "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "Collecting pytest\n",
            "  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/envs/jiant/lib/python3.6/site-packages (from allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/envs/jiant/lib/python3.6/site-packages (from allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (1.5.2)\n",
            "Collecting awscli>=1.11.91\n",
            "  Downloading awscli-1.24.10-py3-none-any.whl (3.9 MB)\n",
            "Collecting flask-cors>=3.0.7\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Collecting parsimonious>=0.8.0\n",
            "  Downloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.23.10-py3-none-any.whl (132 kB)\n",
            "Collecting protobuf>=0.3.2\n",
            "  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: six in /usr/local/envs/jiant/lib/python3.6/site-packages (from tensorboardX==1.2->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 4)) (1.16.0)\n",
            "Collecting python-http-client>=3.0\n",
            "  Downloading python_http_client-3.3.7-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/envs/jiant/lib/python3.6/site-packages (from pyhocon==0.3.35->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 6)) (3.0.4)\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.6.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/envs/jiant/lib/python3.6/site-packages (from pre-commit==1.15.2->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 8)) (5.4.1)\n",
            "Collecting aspy.yaml\n",
            "  Downloading aspy.yaml-1.3.0-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.4.4-py2.py3-none-any.whl (98 kB)\n",
            "Collecting cfgv>=1.4.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting virtualenv>=15.2\n",
            "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/jiant/lib/python3.6/site-packages (from python-Levenshtein==0.12.0->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 9)) (58.0.4)\n",
            "Collecting google-api-core[grpc]<2.0.0dev,>=1.6.0\n",
            "  Downloading google_api_core-1.32.0-py2.py3-none-any.whl (93 kB)\n",
            "Collecting google-cloud-core<2.0dev,>=1.0.0\n",
            "  Downloading google_cloud_core-1.7.3-py2.py3-none-any.whl (28 kB)\n",
            "Collecting thinc<7.1.0,>=7.0.2\n",
            "  Downloading thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.10-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Collecting jsonschema<3.0.0,>=2.6.0\n",
            "  Downloading jsonschema-2.6.0-py2.py3-none-any.whl (39 kB)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83 kB)\n",
            "Collecting srsly<1.1.0,>=0.0.5\n",
            "  Downloading srsly-1.0.7-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (367 kB)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting wasabi<1.1.0,>=0.0.12\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (44 kB)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2 MB)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.2.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting regex\n",
            "  Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\n",
            "Collecting ipython<7.17.0,>=7.16.3\n",
            "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
            "Collecting tomli\n",
            "  Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (5.1.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/jiant/lib/python3.6/site-packages (from tensorboard->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 3)) (0.37.1)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "Collecting click\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/envs/jiant/lib/python3.6/site-packages (from sacremoses->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 13)) (1.0.1)\n",
            "Collecting botocore==1.26.10\n",
            "  Downloading botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
            "Collecting docutils<0.17,>=0.10\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting colorama<0.4.5,>=0.2.5\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/envs/jiant/lib/python3.6/site-packages (from botocore==1.26.10->awscli>=1.11.91->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from flask>=1.0.2->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (3.0.3)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.5.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n",
            "Collecting greenlet>=2.0.0\n",
            "  Downloading greenlet-2.0.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (564 kB)\n",
            "Collecting zope.event\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/envs/jiant/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging==1.11.0->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 10)) (21.3)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
            "  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.17.2)\n",
            "Requirement already satisfied: pygments in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (2.11.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (3.0.20)\n",
            "Requirement already satisfied: pickleshare in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/envs/jiant/lib/python3.6/site-packages (from ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (4.3.3)\n",
            "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from jedi<=0.17.2,>=0.10->ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from Jinja2>=3.0->flask>=1.0.2->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (2.0.1)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/envs/jiant/lib/python3.6/site-packages (from importlib-metadata->pre-commit==1.15.2->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 8)) (4.1.1)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from matplotlib>=2.2.3->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (8.3.1)\n",
            "Collecting sphinx>=1.6.5\n",
            "  Downloading sphinx-5.3.0-py3-none-any.whl (3.2 MB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/jiant/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.2.5)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/jiant/lib/python3.6/site-packages (from requests>=2.18->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (2021.5.30)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "Collecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "Collecting snowballstemmer>=2.0\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "Collecting imagesize>=1.3\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "Collecting babel>=2.9\n",
            "  Downloading Babel-2.11.0-py3-none-any.whl (9.5 MB)\n",
            "Collecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "Collecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "Collecting alabaster<0.8,>=0.7\n",
            "  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/jiant/lib/python3.6/site-packages (from torch>=0.4.1->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/envs/jiant/lib/python3.6/site-packages (from traitlets>=4.2->ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.2.0)\n",
            "Collecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "Collecting filelock<4,>=3.4.1\n",
            "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/envs/jiant/lib/python3.6/site-packages (from pexpect->ipython<7.17.0,>=7.16.3->ipdb->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 2)) (0.7.0)\n",
            "Collecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
            "Collecting py>=1.8.2\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "Collecting attrs>=19.2.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from scikit-learn->allennlp==0.8.4->-r /root/tiny-blimp-eval/jiant/condaenv.6euspoxn.requirements.txt (line 1)) (2.2.0)\n",
            "Building wheels for collected packages: pyhocon, python-Levenshtein, nltk, sacremoses, jsonnet, word2number, ftfy\n",
            "  Building wheel for pyhocon (setup.py): started\n",
            "  Building wheel for pyhocon (setup.py): finished with status 'done'\n",
            "  Created wheel for pyhocon: filename=pyhocon-0.3.35-py3-none-any.whl size=14122 sha256=7307853a5535612c6e8fbe2141825664bd25743bf7f50dbd991731391bfa2f89\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/35/24/db051cb5fa09b0d46084d5e7c5eb8508e75e46963a6826d89d\n",
            "  Building wheel for python-Levenshtein (setup.py): started\n",
            "  Building wheel for python-Levenshtein (setup.py): finished with status 'done'\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=165497 sha256=99a837e7e326804a2667d5fceeb5ae89bfb45c4a8f9b6f2b13d5c2917584b335\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/c3/a1/cbdd8b154234b3e571d121b65be7d53354cc77e223e8f271c8\n",
            "  Building wheel for nltk (setup.py): started\n",
            "  Building wheel for nltk (setup.py): finished with status 'done'\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=518b7e17271c7c0900c72ff18a0ee6c6894ec09ac025f69642955611bcbe103d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/c9/b0/ed26a73ef75a53145820825afa8e2d2c9b30fe9f6c10cd3202\n",
            "  Building wheel for sacremoses (setup.py): started\n",
            "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=a42ff0dae3f9cc213128606de529a83b338798fdeb8fd7acb7a7bb12c563df0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\n",
            "  Building wheel for jsonnet (setup.py): started\n",
            "  Building wheel for jsonnet (setup.py): finished with status 'done'\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp36-cp36m-linux_x86_64.whl size=6410300 sha256=6143a1f86f6354636796fbabe32d2c28c193df49b424c956558a7c14f81204f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/01/10/f7fc519f928e658e4b4b7270a4b61a74e2039899b817fe187d\n",
            "  Building wheel for word2number (setup.py): started\n",
            "  Building wheel for word2number (setup.py): finished with status 'done'\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=5e4a0d7c2a2f46a6c05a76e78032bcbc94faabde3f00303119b6085e87264ef8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/5e/36/8b922f014b64e2a45bac622008bc439281784eb1e09fe5d8d5\n",
            "  Building wheel for ftfy (setup.py): started\n",
            "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=d453cd3bce24db49c6f4d7b59ec12121336971ed4460471e2705e52c15566e79\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/2a/24/75041425faf3347ab146a4a3d0484f723b2c44a7966a06e3f0\n",
            "Successfully built pyhocon python-Levenshtein nltk sacremoses jsonnet word2number ftfy\n",
            "Installing collected packages: zipp, urllib3, pyasn1, jmespath, rsa, pyasn1-modules, protobuf, importlib-resources, importlib-metadata, idna, cymem, charset-normalizer, cachetools, botocore, werkzeug, wasabi, tqdm, srsly, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, snowballstemmer, s3transfer, requests, pygments, preshed, plac, oauthlib, murmurhash, itsdangerous, imagesize, googleapis-common-protos, google-auth, docutils, click, blis, babel, alabaster, zope.interface, zope.event, tomli, thinc, sphinx, requests-oauthlib, regex, py, pluggy, platformdirs, kiwisolver, jsonschema, iniconfig, grpcio, greenlet, google-api-core, flask, filelock, distlib, cycler, colorama, cached-property, boto3, attrs, word2number, virtualenv, unidecode, toml, tensorboardX, tensorboard-plugin-wit, tensorboard-data-server, sqlparse, spacy, sentencepiece, responses, pytorch-pretrained-bert, python-http-client, pytest, parsimonious, overrides, numpydoc, nodeenv, nltk, matplotlib, markdown, jsonpickle, jsonnet, ipython, identify, h5py, google-cloud-core, google-auth-oauthlib, gevent, ftfy, flask-cors, flaky, editdistance, conllu, cfgv, awscli, aspy.yaml, absl-py, tensorboard, sendgrid, sacremoses, pytorch-transformers, python-Levenshtein, pyhocon, pre-commit, nose2, ipdb, google-cloud-logging, allennlp\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.11.2\n",
            "    Uninstalling Pygments-2.11.2:\n",
            "      Successfully uninstalled Pygments-2.11.2\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.16.1\n",
            "    Uninstalling ipython-7.16.1:\n",
            "      Successfully uninstalled ipython-7.16.1\n",
            "Successfully installed absl-py-1.4.0 alabaster-0.7.13 allennlp-0.8.4 aspy.yaml-1.3.0 attrs-22.2.0 awscli-1.24.10 babel-2.11.0 blis-0.2.4 boto3-1.23.10 botocore-1.26.10 cached-property-1.5.2 cachetools-4.2.4 cfgv-3.3.1 charset-normalizer-2.0.12 click-8.0.4 colorama-0.4.4 conllu-0.11 cycler-0.11.0 cymem-2.0.8 distlib-0.3.9 docutils-0.16 editdistance-0.6.2 filelock-3.4.1 flaky-3.8.1 flask-2.0.3 flask-cors-5.0.0 ftfy-6.0.3 gevent-22.10.2 google-api-core-1.32.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-cloud-core-1.7.3 google-cloud-logging-1.11.0 googleapis-common-protos-1.56.3 greenlet-2.0.2 grpcio-1.48.2 h5py-3.1.0 identify-2.4.4 idna-3.10 imagesize-1.4.1 importlib-metadata-4.8.3 importlib-resources-5.4.0 iniconfig-1.1.1 ipdb-0.13.13 ipython-7.16.3 itsdangerous-2.0.1 jmespath-0.10.0 jsonnet-0.20.0 jsonpickle-2.2.0 jsonschema-2.6.0 kiwisolver-1.3.1 markdown-3.3.7 matplotlib-3.3.4 murmurhash-1.0.10 nltk-3.4.5 nodeenv-1.6.0 nose2-0.13.0 numpydoc-1.1.0 oauthlib-3.2.2 overrides-7.7.0 parsimonious-0.10.0 plac-0.9.6 platformdirs-2.4.0 pluggy-1.0.0 pre-commit-1.15.2 preshed-2.0.1 protobuf-3.19.6 py-1.11.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pygments-2.14.0 pyhocon-0.3.35 pytest-7.0.1 python-Levenshtein-0.12.0 python-http-client-3.3.7 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 regex-2023.8.8 requests-2.27.1 requests-oauthlib-2.0.0 responses-0.17.0 rsa-4.7.2 s3transfer-0.5.2 sacremoses-0.0.53 sendgrid-5.4.1 sentencepiece-0.2.0 snowballstemmer-2.2.0 spacy-2.1.0 sphinx-5.3.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sqlparse-0.4.4 srsly-1.0.7 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-1.2 thinc-7.0.8 toml-0.10.2 tomli-1.2.3 tqdm-4.64.1 unidecode-1.3.8 urllib3-1.26.20 virtualenv-20.17.1 wasabi-0.10.1 werkzeug-2.0.3 word2number-1.1 zipp-3.6.0 zope.event-4.6 zope.interface-5.5.2\n",
            "\n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate jiant\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python -m pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hsuJFsLsGIL",
        "outputId": "89ca0d25-2720-4992-f3b4-8b5826700f40",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "absl-py==1.4.0\n",
            "alabaster==0.7.13\n",
            "allennlp==0.8.4\n",
            "aspy.yaml==1.3.0\n",
            "attrs==22.2.0\n",
            "awscli==1.24.10\n",
            "Babel==2.11.0\n",
            "backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\n",
            "blis==0.2.4\n",
            "bokeh==1.2.0\n",
            "boto3==1.23.10\n",
            "botocore==1.26.10\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.4\n",
            "certifi==2021.5.30\n",
            "cfgv==3.3.1\n",
            "charset-normalizer==2.0.12\n",
            "click==8.0.4\n",
            "colorama==0.4.4\n",
            "conllu==0.11\n",
            "cycler==0.11.0\n",
            "cymem==2.0.8\n",
            "dataclasses @ file:///tmp/build/80754af9/dataclasses_1614363715916/work\n",
            "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\n",
            "distlib==0.3.9\n",
            "docutils==0.16\n",
            "editdistance==0.6.2\n",
            "entrypoints==0.3\n",
            "filelock==3.4.1\n",
            "flaky==3.8.1\n",
            "Flask==2.0.3\n",
            "Flask-Cors==5.0.0\n",
            "ftfy==6.0.3\n",
            "gevent==22.10.2\n",
            "google-api-core==1.32.0\n",
            "google-auth==1.35.0\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-core==1.7.3\n",
            "google-cloud-logging==1.11.0\n",
            "googleapis-common-protos==1.56.3\n",
            "greenlet==2.0.2\n",
            "grpcio==1.48.2\n",
            "h5py==3.1.0\n",
            "identify==2.4.4\n",
            "idna==3.10\n",
            "imagesize==1.4.1\n",
            "importlib-metadata==4.8.3\n",
            "importlib-resources==5.4.0\n",
            "iniconfig==1.1.1\n",
            "ipdb==0.13.13\n",
            "ipykernel==5.1.1\n",
            "ipython==7.16.3\n",
            "ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work\n",
            "itsdangerous==2.0.1\n",
            "jedi @ file:///tmp/build/80754af9/jedi_1606932572482/work\n",
            "Jinja2 @ file:///opt/conda/conda-bld/jinja2_1647436528585/work\n",
            "jmespath==0.10.0\n",
            "joblib @ file:///tmp/build/80754af9/joblib_1613502643832/work\n",
            "jsondiff @ file:///tmp/build/80754af9/jsondiff_1619041728110/work\n",
            "jsonnet==0.20.0\n",
            "jsonpickle==2.2.0\n",
            "jsonschema==2.6.0\n",
            "jupyter-client @ file:///opt/conda/conda-bld/jupyter_client_1643638337975/work\n",
            "jupyter-core @ file:///tmp/build/80754af9/jupyter_core_1633420100582/work\n",
            "kiwisolver==1.3.1\n",
            "Markdown==3.3.7\n",
            "MarkupSafe @ file:///tmp/build/80754af9/markupsafe_1621528150516/work\n",
            "matplotlib==3.3.4\n",
            "mkl-fft==1.3.0\n",
            "mkl-random==1.1.1\n",
            "mkl-service==2.3.0\n",
            "murmurhash==1.0.10\n",
            "nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1613680548246/work\n",
            "nltk==3.4.5\n",
            "nodeenv==1.6.0\n",
            "nose2==0.13.0\n",
            "numpy @ file:///tmp/build/80754af9/numpy_and_numpy_base_1603487797006/work\n",
            "numpydoc==1.1.0\n",
            "oauthlib==3.2.2\n",
            "olefile @ file:///Users/ktietz/demo/mc3/conda-bld/olefile_1629805411829/work\n",
            "overrides==7.7.0\n",
            "packaging @ file:///tmp/build/80754af9/packaging_1637314298585/work\n",
            "pandas==1.1.5\n",
            "parsimonious==0.10.0\n",
            "parso==0.7.0\n",
            "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\n",
            "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\n",
            "Pillow @ file:///tmp/build/80754af9/pillow_1625670622947/work\n",
            "plac==0.9.6\n",
            "platformdirs==2.4.0\n",
            "pluggy==1.0.0\n",
            "pre-commit==1.15.2\n",
            "preshed==2.0.1\n",
            "prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1633440160888/work\n",
            "protobuf==3.19.6\n",
            "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
            "py==1.11.0\n",
            "pyasn1==0.5.1\n",
            "pyasn1-modules==0.3.0\n",
            "Pygments==2.14.0\n",
            "pyhocon==0.3.35\n",
            "pyparsing @ file:///tmp/build/80754af9/pyparsing_1635766073266/work\n",
            "pytest==7.0.1\n",
            "python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\n",
            "python-http-client==3.3.7\n",
            "python-Levenshtein==0.12.0\n",
            "pytorch-pretrained-bert==0.6.2\n",
            "pytorch-transformers==1.1.0\n",
            "pytz==2017.3\n",
            "PyYAML==5.4.1\n",
            "pyzmq @ file:///tmp/build/80754af9/pyzmq_1628268400816/work\n",
            "regex==2023.8.8\n",
            "requests==2.27.1\n",
            "requests-oauthlib==2.0.0\n",
            "responses==0.17.0\n",
            "rsa==4.7.2\n",
            "s3transfer==0.5.2\n",
            "sacremoses==0.0.53\n",
            "scikit-learn @ file:///tmp/build/80754af9/scikit-learn_1621365798935/work\n",
            "scipy @ file:///tmp/build/80754af9/scipy_1597686625380/work\n",
            "sendgrid==5.4.1\n",
            "sentencepiece==0.2.0\n",
            "six @ file:///tmp/build/80754af9/six_1644875935023/work\n",
            "snowballstemmer==2.2.0\n",
            "spacy==2.1.0\n",
            "Sphinx==5.3.0\n",
            "sphinxcontrib-applehelp==1.0.2\n",
            "sphinxcontrib-devhelp==1.0.2\n",
            "sphinxcontrib-htmlhelp==2.0.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.3\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sqlparse==0.4.4\n",
            "srsly==1.0.7\n",
            "tensorboard==2.10.1\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorboardX==1.2\n",
            "thinc==7.0.8\n",
            "threadpoolctl @ file:///Users/ktietz/demo/mc3/conda-bld/threadpoolctl_1629802263681/work\n",
            "toml==0.10.2\n",
            "tomli==1.2.3\n",
            "torch==1.10.2\n",
            "torchvision==0.11.3\n",
            "tornado @ file:///tmp/build/80754af9/tornado_1606942266872/work\n",
            "tqdm==4.64.1\n",
            "traitlets @ file:///tmp/build/80754af9/traitlets_1632746497744/work\n",
            "typing_extensions @ file:///opt/conda/conda-bld/typing_extensions_1647553014482/work\n",
            "Unidecode==1.3.8\n",
            "urllib3==1.26.20\n",
            "virtualenv==20.17.1\n",
            "wasabi==0.10.1\n",
            "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
            "Werkzeug==2.0.3\n",
            "word2number==1.1\n",
            "zipp==3.6.0\n",
            "zope.event==4.6\n",
            "zope.interface==5.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env JIANT_PROJECT_PREFIX=jiant\n",
        "%env JIANT_DATA_DIR=tiny-blimp-eval/data\n",
        "%env WORD_EMBS_FILE=None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNdE07p-4aqy",
        "outputId": "0aca7e2e-eeaa-4522-c94a-fa85ff41f5e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: JIANT_PROJECT_PREFIX=jiant\n",
            "env: JIANT_DATA_DIR=tiny-blimp-eval/data\n",
            "env: WORD_EMBS_FILE=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python -m nltk.downloader perluniprops nonbreaking_prefixes punkt"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wJyuoAYIjsr",
        "outputId": "e63eb866-2e34-4414-9b3d-49cfbca004d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/envs/jiant/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python -m spacy download en"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLFKqVPqIoyW",
        "outputId": "fa033c10-4b87-47b5-9121-bc30f96fdd7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 3.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074433 sha256=7972fb431580e4a2a8265eb0c64cc607d607c971d0327e2a6497607a62ed2fa1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d_1cayt6/wheels/57/3c/44/bac9773a437855dc01e9bf30fc2064610227be5e94a84cd680\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/envs/jiant/lib/python3.6/site-packages/en_core_web_sm -->\n",
            "/usr/local/envs/jiant/lib/python3.6/site-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python -m pip install overrides==3.1.0"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhrPQ7lyIrWS",
        "outputId": "3840410c-8876-4093-b3b6-29fe8ba73b51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=48f1f0aa698aa056d3fdbdf053c695456edee95515aa27ade98d288965795919\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/3b/34/ae59fc8d35c37f01099425ab73599e45e9b9b599a7ccc2c45f\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.7.0\n",
            "    Uninstalling overrides-7.7.0:\n",
            "      Successfully uninstalled overrides-7.7.0\n",
            "Successfully installed overrides-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python -m pip install --upgrade transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDRTRkWDI32X",
        "outputId": "46051cb4-3e54-4330-9e6b-0f7e059530e4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/envs/jiant/lib/python3.6/site-packages (4.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (4.8.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/envs/jiant/lib/python3.6/site-packages (from transformers) (1.19.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/envs/jiant/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/envs/jiant/lib/python3.6/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/envs/jiant/lib/python3.6/site-packages (from tqdm>=4.27->transformers) (5.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/envs/jiant/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/jiant/lib/python3.6/site-packages (from requests->transformers) (1.26.20)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/jiant/lib/python3.6/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/jiant/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/envs/jiant/lib/python3.6/site-packages (from sacremoses->transformers) (8.0.4)\n",
            "Requirement already satisfied: six in /usr/local/envs/jiant/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/envs/jiant/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python -m pip install --upgrade pip setuptools wheel"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OZt5ajNEx4n_",
        "outputId": "7f3045b9-7b6c-4398-9e83-0c2802d6a418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/envs/jiant/lib/python3.6/site-packages (21.2.2)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/envs/jiant/lib/python3.6/site-packages (58.0.4)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-59.6.0-py3-none-any.whl (952 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/envs/jiant/lib/python3.6/site-packages (0.37.1)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 58.0.4\n",
            "    Uninstalling setuptools-58.0.4:\n",
            "      Successfully uninstalled setuptools-58.0.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.2.2\n",
            "    Uninstalling pip-21.2.2:\n",
            "      Successfully uninstalled pip-21.2.2\n",
            "Successfully installed pip-21.3.1 setuptools-59.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downgrade scikit-learn to 0.22 in jiant environment\n",
        "\n",
        "!/usr/local/envs/jiant/bin/python -m pip install scikit-learn==0.22"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtV5mI9xK18V",
        "outputId": "8cce5791-6699-4423-968f-0b7317882a0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.22\n",
            "  Downloading scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from scikit-learn==0.22) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/envs/jiant/lib/python3.6/site-packages (from scikit-learn==0.22) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/envs/jiant/lib/python3.6/site-packages (from scikit-learn==0.22) (1.19.2)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.24.2\n",
            "    Uninstalling scikit-learn-0.24.2:\n",
            "      Successfully uninstalled scikit-learn-0.24.2\n",
            "Successfully installed scikit-learn-0.22\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes:\n",
        "\n",
        "After running the above, we have the jiant environment and the following directories of interest:\n",
        "\n",
        "Concatenated .jsonl data files as : root/tiny-blimp-eval/data/blimp/blimp.jsonl\n",
        "\n",
        "Config file (currently just the default gpt2 one, and I override in the actual command in next cell): tiny-blimp-eval/jiant/jiant/config/blimp/blimp_gpt2.conf\n",
        "\n",
        "And tiny-blimp-eval/jiant/jiant/models.py, which I'm trying to edit to pull the checkpoint model for evaluation. You'll see errors in the below cell, and I'm not sure where to go from here. I'm just trying to do a single checkpoint for now (specifically, the first one, 500).\n"
      ],
      "metadata": {
        "id": "erQXaNgQVDVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "SoWKJJ2-QdIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!rm -rf tiny_gpt2_tiny_stories\n",
        "!git clone https://huggingface.co/rock-z/tiny_gpt2_tiny_stories"
      ],
      "metadata": {
        "id": "XXN7XC9N1C98",
        "outputId": "9fe65c0d-d572-43ad-f72c-1d155055f94d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'tiny_gpt2_tiny_stories'...\n",
            "remote: Enumerating objects: 1000, done.\u001b[K\n",
            "remote: Counting objects: 100% (997/997), done.\u001b[K\n",
            "remote: Compressing objects: 100% (997/997), done.\u001b[K\n",
            "remote: Total 1000 (delta 293), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1000/1000), 272.00 KiB | 7.35 MiB/s, done.\n",
            "Resolving deltas: 100% (293/293), done.\n",
            "Filtering content: 100% (497/497), 4.06 GiB | 67.20 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf tiny-blimp-eval/\n",
        "# !rm -rf jiant\n",
        "!git clone https://github.com/laslil7437/tiny-blimp-eval.git"
      ],
      "metadata": {
        "id": "5UjACu17uAY8",
        "outputId": "58063ee7-c1d8-4360-b1ba-bb029a9a3a37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tiny-blimp-eval'...\n",
            "remote: Enumerating objects: 398, done.\u001b[K\n",
            "remote: Counting objects: 100% (398/398), done.\u001b[K\n",
            "remote: Compressing objects: 100% (342/342), done.\u001b[K\n",
            "remote: Total 398 (delta 132), reused 266 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (398/398), 1.35 MiB | 4.19 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/envs/jiant/bin/python tiny-blimp-eval/jiant/main.py --config_file tiny-blimp-eval/jiant/jiant/config/blimp/blimp_gpt2.conf --overrides=\"exp_name=blimp-gpt2,run_name=ckpt500,target_tasks=blimp-simpleLM,input_module=tiny\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D_NP0NZgQfte",
        "outputId": "9b6e5c53-027c-4ed3-d5c0-f6a14881cd92"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/20 07:06:29 PM: Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "/usr/local/envs/jiant/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n",
            "11/20 07:06:30 PM: Loading config from tiny-blimp-eval/jiant/jiant/config/blimp/blimp_gpt2.conf\n",
            "11/20 07:06:30 PM: Config overrides: exp_name=blimp-gpt2,run_name=ckpt500,target_tasks=blimp-simpleLM,input_module=tiny\n",
            "11/20 07:06:31 PM: Git branch: main\n",
            "11/20 07:06:31 PM: Git SHA: 76e575ed66aa9dd6c483c11c2fae5f300c511f72\n",
            "11/20 07:06:31 PM: Parsed args: \n",
            "{\n",
            "  \"allow_missing_task_map\": 1,\n",
            "  \"allow_untrained_encoder_parameters\": 1,\n",
            "  \"do_pretrain\": 0,\n",
            "  \"do_target_task_training\": 0,\n",
            "  \"exp_dir\": \"jiant/blimp-gpt2/\",\n",
            "  \"exp_name\": \"blimp-gpt2\",\n",
            "  \"input_module\": \"tiny\",\n",
            "  \"local_log_path\": \"jiant/blimp-gpt2/ckpt500/log.log\",\n",
            "  \"pretrain_tasks\": \"\",\n",
            "  \"remote_log_name\": \"blimp-gpt2__ckpt500\",\n",
            "  \"run_dir\": \"jiant/blimp-gpt2/ckpt500\",\n",
            "  \"run_name\": \"ckpt500\",\n",
            "  \"sent_enc\": \"none\",\n",
            "  \"sep_embs_for_skip\": 1,\n",
            "  \"target_tasks\": \"blimp-simpleLM\",\n",
            "  \"write_preds\": \"val\"\n",
            "}\n",
            "11/20 07:06:31 PM: Saved config to jiant/blimp-gpt2/ckpt500/params.conf\n",
            "11/20 07:06:31 PM: Using random seed 1234\n",
            "11/20 07:06:31 PM: GPU access failed. You might be using a CPU-only installation of PyTorch. Falling back to CPU.\n",
            "11/20 07:06:31 PM: Loading tasks...\n",
            "11/20 07:06:31 PM: Writing pre-preprocessed tasks to jiant/blimp-gpt2/\n",
            "11/20 07:06:31 PM: \tLoaded existing task blimp-simpleLM\n",
            "11/20 07:06:31 PM: \tTask 'blimp-simpleLM': |train|=10000 |val|=10000 |test|=10000\n",
            "11/20 07:06:31 PM: \tFinished loading tasks: blimp-simpleLM.\n",
            "11/20 07:06:31 PM: Loading token dictionary from jiant/blimp-gpt2/vocab.\n",
            "11/20 07:06:31 PM: \tLoaded vocab from jiant/blimp-gpt2/vocab\n",
            "11/20 07:06:31 PM: \tVocab namespace chars: size 54\n",
            "11/20 07:06:31 PM: \tVocab namespace tokens: size 1953\n",
            "11/20 07:06:31 PM: \tFinished building vocab.\n",
            "11/20 07:06:31 PM: \tTask 'blimp-simpleLM', split 'train': Found preprocessed copy in jiant/blimp-gpt2/preproc/blimp-simpleLM__train_data\n",
            "11/20 07:06:31 PM: \tTask 'blimp-simpleLM', split 'val': Found preprocessed copy in jiant/blimp-gpt2/preproc/blimp-simpleLM__val_data\n",
            "11/20 07:06:31 PM: \tTask 'blimp-simpleLM', split 'test': Found preprocessed copy in jiant/blimp-gpt2/preproc/blimp-simpleLM__test_data\n",
            "11/20 07:06:31 PM: \tFinished indexing tasks\n",
            "11/20 07:06:31 PM: \tCreating trimmed target-only version of blimp-simpleLM train.\n",
            "11/20 07:06:31 PM: \t  Training on \n",
            "11/20 07:06:31 PM: \t  Evaluating on blimp-simpleLM\n",
            "11/20 07:06:31 PM: \tFinished loading tasks in 0.041s\n",
            "11/20 07:06:31 PM: \t Tasks: ['blimp-simpleLM']\n",
            "11/20 07:06:31 PM: Building model...\n",
            "11/20 07:06:32 PM: Fatal error in main():\n",
            "Traceback (most recent call last):\n",
            "  File \"tiny-blimp-eval/jiant/main.py\", line 16, in <module>\n",
            "    main(sys.argv[1:])\n",
            "  File \"/root/tiny-blimp-eval/jiant/jiant/__main__.py\", line 510, in main\n",
            "    model = build_model(args, vocab, word_embs, tasks)\n",
            "  File \"/root/tiny-blimp-eval/jiant/jiant/models.py\", line 252, in build_model\n",
            "    model = AutoModelForCausalLM.from_pretrained(\"./tiny_gpt2_tiny_stories/checkpoint-500\", use_safetensors=True)\n",
            "  File \"/usr/local/envs/jiant/lib/python3.6/site-packages/transformers/models/auto/auto_factory.py\", line 446, in from_pretrained\n",
            "    return model_class.from_pretrained(pretrained_model_name_or_path, *model_args, config=config, **kwargs)\n",
            "  File \"/usr/local/envs/jiant/lib/python3.6/site-packages/transformers/modeling_utils.py\", line 1635, in from_pretrained\n",
            "    f\"Error no file named {WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} but \"\n",
            "OSError: Error no file named pytorch_model.bin found in directory ./tiny_gpt2_tiny_stories/checkpoint-500 but there is a file for Flax weights. Use `from_flax=True` to load this model from those weights.\n",
            "Traceback (most recent call last):\n",
            "  File \"tiny-blimp-eval/jiant/main.py\", line 27, in <module>\n",
            "    raise e  # re-raise exception, in case debugger is attached.\n",
            "  File \"tiny-blimp-eval/jiant/main.py\", line 16, in <module>\n",
            "    main(sys.argv[1:])\n",
            "  File \"/root/tiny-blimp-eval/jiant/jiant/__main__.py\", line 510, in main\n",
            "    model = build_model(args, vocab, word_embs, tasks)\n",
            "  File \"/root/tiny-blimp-eval/jiant/jiant/models.py\", line 252, in build_model\n",
            "    model = AutoModelForCausalLM.from_pretrained(\"./tiny_gpt2_tiny_stories/checkpoint-500\", use_safetensors=True)\n",
            "  File \"/usr/local/envs/jiant/lib/python3.6/site-packages/transformers/models/auto/auto_factory.py\", line 446, in from_pretrained\n",
            "    return model_class.from_pretrained(pretrained_model_name_or_path, *model_args, config=config, **kwargs)\n",
            "  File \"/usr/local/envs/jiant/lib/python3.6/site-packages/transformers/modeling_utils.py\", line 1635, in from_pretrained\n",
            "    f\"Error no file named {WEIGHTS_NAME} found in directory {pretrained_model_name_or_path} but \"\n",
            "OSError: Error no file named pytorch_model.bin found in directory ./tiny_gpt2_tiny_stories/checkpoint-500 but there is a file for Flax weights. Use `from_flax=True` to load this model from those weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat tiny-blimp-eval/jiant/jiant/models.py"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3DhXiyKD48oA",
        "outputId": "eab2f915-d4d9-42d3-99d6-ad0e195dd391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\"\"Core model and functions for building it.\"\"\"\n",
            "import copy\n",
            "import json\n",
            "import logging as log\n",
            "import os\n",
            "\n",
            "import numpy as np\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "\n",
            "from allennlp.common import Params\n",
            "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder as s2s_e\n",
            "from allennlp.modules.seq2seq_encoders import StackedSelfAttentionEncoder\n",
            "from allennlp.modules.seq2vec_encoders import CnnEncoder\n",
            "from allennlp.modules.token_embedders import Embedding, TokenCharactersEncoder\n",
            "from allennlp.training.metrics import Average\n",
            "from sklearn.metrics import mean_squared_error\n",
            "\n",
            "from jiant.allennlp_mods.elmo_text_field_embedder import (\n",
            "    ElmoTextFieldEmbedder,\n",
            "    ElmoTokenEmbedderWrapper,\n",
            ")\n",
            "\n",
            "from jiant.modules.edge_probing import EdgeClassifierModule\n",
            "from jiant.modules.simple_modules import (\n",
            "    Pooler,\n",
            "    Classifier,\n",
            "    SingleClassifier,\n",
            "    PairClassifier,\n",
            "    NullPhraseLayer,\n",
            ")\n",
            "from jiant.modules.attn_pair_encoder import AttnPairEncoder\n",
            "from jiant.modules.sentence_encoder import SentenceEncoder\n",
            "from jiant.modules.bilm_encoder import BiLMEncoder\n",
            "from jiant.modules.bow_sentence_encoder import BoWSentEncoder\n",
            "from jiant.modules.elmo_character_encoder import ElmoCharacterEncoder\n",
            "from jiant.modules.onlstm_phrase_layer import ONLSTMPhraseLayer\n",
            "from jiant.modules.prpn_phrase_layer import PRPNPhraseLayer\n",
            "from jiant.modules.onlstm.ON_LSTM import ONLSTMStack\n",
            "from jiant.modules.prpn.PRPN import PRPN\n",
            "from jiant.modules.seq2seq_decoder import Seq2SeqDecoder\n",
            "from jiant.modules.span_modules import SpanClassifierModule\n",
            "from jiant.pytorch_transformers_interface import input_module_uses_pytorch_transformers\n",
            "from jiant.tasks.edge_probing import EdgeProbingTask\n",
            "from jiant.tasks.lm import LanguageModelingTask\n",
            "from jiant.tasks.lm_parsing import LanguageModelingParsingTask\n",
            "from jiant.tasks.qa import MultiRCTask, ReCoRDTask\n",
            "from jiant.tasks.seq2seq import Seq2SeqTask\n",
            "from jiant.tasks.tasks import (\n",
            "    GLUEDiagnosticTask,\n",
            "    MultipleChoiceTask,\n",
            "    PairClassificationTask,\n",
            "    PairOrdinalRegressionTask,\n",
            "    PairRegressionTask,\n",
            "    RegressionTask,\n",
            "    SequenceGenerationTask,\n",
            "    SingleClassificationTask,\n",
            "    SpanClassificationTask,\n",
            "    STSBTask,\n",
            "    TaggingTask,\n",
            "    WiCTask,\n",
            "    MRPCTask,\n",
            "    QQPTask,\n",
            ")\n",
            "from jiant.tasks.acceptablity_probing import (\n",
            "    NPIMinimalPairTask,\n",
            "    NPIClozePairTask,\n",
            "    BlimpTask,\n",
            "    BlimpOnePrefixLMTask,\n",
            "    BlimpTwoPrefixLMTask,\n",
            "    BlimpFullSentLMTask,\n",
            ")\n",
            "from jiant.utils import config\n",
            "from jiant.utils.utils import (\n",
            "    assert_for_log,\n",
            "    get_batch_size,\n",
            "    get_batch_utilization,\n",
            "    get_elmo_mixing_weights,\n",
            "    maybe_make_dir,\n",
            ")\n",
            "\n",
            "# Elmo stuff\n",
            "# Look in $ELMO_SRC_DIR (e.g. /usr/share/jsalt/elmo) or download from web\n",
            "ELMO_OPT_NAME = \"elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
            "ELMO_WEIGHTS_NAME = \"elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
            "ELMO_SRC_DIR = (\n",
            "    os.getenv(\"ELMO_SRC_DIR\")\n",
            "    or \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/\"\n",
            ")\n",
            "ELMO_OPT_PATH = os.path.join(ELMO_SRC_DIR, ELMO_OPT_NAME)\n",
            "ELMO_WEIGHTS_PATH = os.path.join(ELMO_SRC_DIR, ELMO_WEIGHTS_NAME)\n",
            "\n",
            "\n",
            "def build_sent_encoder(args, vocab, d_emb, tasks, embedder, cove_layer):\n",
            "    # Build single sentence encoder: the main component of interest\n",
            "    # Need special handling for language modeling\n",
            "    # Note: sent_enc is expected to apply dropout to its input _and_ output if\n",
            "    # needed.\n",
            "    rnn_params = Params(\n",
            "        {\n",
            "            \"input_size\": d_emb,\n",
            "            \"bidirectional\": True,\n",
            "            \"hidden_size\": args.d_hid,\n",
            "            \"num_layers\": args.n_layers_enc,\n",
            "        }\n",
            "    )\n",
            "    if args.sent_enc == \"onlstm\":\n",
            "        onlayer = ONLSTMPhraseLayer(\n",
            "            vocab,\n",
            "            args.d_word,\n",
            "            args.d_hid,\n",
            "            args.n_layers_enc,\n",
            "            args.onlstm_chunk_size,\n",
            "            args.onlstm_dropconnect,\n",
            "            args.onlstm_dropouti,\n",
            "            args.dropout,\n",
            "            args.onlstm_dropouth,\n",
            "            embedder,\n",
            "            args.batch_size,\n",
            "        )\n",
            "        # The 'onlayer' acts as a phrase layer module for the larger SentenceEncoder module.\n",
            "        sent_encoder = SentenceEncoder(\n",
            "            vocab,\n",
            "            embedder,\n",
            "            args.n_layers_highway,\n",
            "            onlayer.onlayer,\n",
            "            skip_embs=args.skip_embs,\n",
            "            dropout=args.dropout,\n",
            "            sep_embs_for_skip=args.sep_embs_for_skip,\n",
            "            cove_layer=cove_layer,\n",
            "        )\n",
            "        d_sent = args.d_word\n",
            "        log.info(\"Using ON-LSTM sentence encoder!\")\n",
            "    elif args.sent_enc == \"prpn\":\n",
            "        prpnlayer = PRPNPhraseLayer(\n",
            "            vocab,\n",
            "            args.d_word,\n",
            "            args.d_hid,\n",
            "            args.n_layers_enc,\n",
            "            args.n_slots,\n",
            "            args.n_lookback,\n",
            "            args.resolution,\n",
            "            args.dropout,\n",
            "            args.idropout,\n",
            "            args.rdropout,\n",
            "            args.res,\n",
            "            embedder,\n",
            "            args.batch_size,\n",
            "        )\n",
            "        # The 'prpn' acts as a phrase layer module for the larger SentenceEncoder module.\n",
            "        sent_encoder = SentenceEncoder(\n",
            "            vocab,\n",
            "            embedder,\n",
            "            args.n_layers_highway,\n",
            "            prpnlayer.prpnlayer,\n",
            "            skip_embs=args.skip_embs,\n",
            "            dropout=args.dropout,\n",
            "            sep_embs_for_skip=args.sep_embs_for_skip,\n",
            "            cove_layer=cove_layer,\n",
            "        )\n",
            "        d_sent = args.d_word\n",
            "        log.info(\"Using PRPN sentence encoder!\")\n",
            "    elif any(isinstance(task, LanguageModelingTask) for task in tasks) or args.sent_enc == \"bilm\":\n",
            "        assert_for_log(args.sent_enc in [\"rnn\", \"bilm\"], \"Only RNNLM supported!\")\n",
            "        assert_for_log(\n",
            "            not (\n",
            "                args.input_module == \"elmo\"\n",
            "                or args.input_module.startswith(\"bert\")\n",
            "                or args.input_module.startswith(\"xlnet\")\n",
            "            ),\n",
            "            f\"Using input_module = {args.input_module} for language modeling is probably not a \"\n",
            "            \"good idea, since it allows the language model to use information from the right-hand \"\n",
            "            \"context.\",\n",
            "        )\n",
            "        bilm = BiLMEncoder(d_emb, args.d_hid, args.d_hid, args.n_layers_enc)\n",
            "        sent_encoder = SentenceEncoder(\n",
            "            vocab,\n",
            "            embedder,\n",
            "            args.n_layers_highway,\n",
            "            bilm,\n",
            "            skip_embs=args.skip_embs,\n",
            "            dropout=args.dropout,\n",
            "            sep_embs_for_skip=args.sep_embs_for_skip,\n",
            "            cove_layer=cove_layer,\n",
            "        )\n",
            "        d_sent = 2 * args.d_hid\n",
            "    elif args.sent_enc == \"bow\":\n",
            "        sent_encoder = BoWSentEncoder(vocab, embedder)\n",
            "        assert_for_log(\n",
            "            not args.skip_embs, \"Skip connection not currently supported with `bow` encoder.\"\n",
            "        )\n",
            "        d_sent = d_emb\n",
            "    elif args.sent_enc == \"rnn\":\n",
            "        sent_rnn = s2s_e.by_name(\"lstm\").from_params(copy.deepcopy(rnn_params))\n",
            "        sent_encoder = SentenceEncoder(\n",
            "            vocab,\n",
            "            embedder,\n",
            "            args.n_layers_highway,\n",
            "            sent_rnn,\n",
            "            skip_embs=args.skip_embs,\n",
            "            dropout=args.dropout,\n",
            "            sep_embs_for_skip=args.sep_embs_for_skip,\n",
            "            cove_layer=cove_layer,\n",
            "        )\n",
            "        d_sent = 2 * args.d_hid\n",
            "    elif args.sent_enc == \"none\":\n",
            "        # Expose word representation layer (GloVe, ELMo, etc.) directly.\n",
            "        assert_for_log(\n",
            "            args.skip_embs,\n",
            "            \"skip_embs is false and sent_enc is none, \"\n",
            "            \"which means that your token representations are zero-dimensional. Consider setting skip_embs.\",\n",
            "        )\n",
            "        phrase_layer = NullPhraseLayer(rnn_params[\"input_size\"])\n",
            "        sent_encoder = SentenceEncoder(\n",
            "            vocab,\n",
            "            embedder,\n",
            "            args.n_layers_highway,\n",
            "            phrase_layer,\n",
            "            skip_embs=args.skip_embs,\n",
            "            dropout=args.dropout,\n",
            "            sep_embs_for_skip=args.sep_embs_for_skip,\n",
            "            cove_layer=cove_layer,\n",
            "        )\n",
            "        d_sent = 0\n",
            "    else:\n",
            "        assert_for_log(\n",
            "            False, f\"Shared encoder layer specification `{args.sent_enc}` not recognized.\"\n",
            "        )\n",
            "    return sent_encoder, d_sent\n",
            "\n",
            "\n",
            "def build_model(args, vocab, pretrained_embs, tasks):\n",
            "    \"\"\"\n",
            "    Build model according to args\n",
            "    Returns: model which has attributes set in it with the attrbutes.\n",
            "    \"\"\"\n",
            "\n",
            "    # Build embeddings.\n",
            "    cove_layer = None\n",
            "    if args.input_module.startswith(\"gpt2\"):\n",
            "        from jiant.pytorch_transformers_interface.modules import GPT2EmbedderModule\n",
            "\n",
            "        log.info(f\"Using GPT-2 model ({args.input_module}).\")\n",
            "        embedder = GPT2EmbedderModule(args)\n",
            "        d_emb = embedder.get_output_dim()\n",
            "        \n",
            "    elif args.input_module.startswith(\"tiny\"):\n",
            "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
            "        tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
            "\t\n",
            "        model = AutoModelForCausalLM.from_pretrained(\"./tiny_gpt2_tiny_stories/checkpoint-500\", safe_model=True, from_flax=True)\n",
            "        \n",
            "        log.info(f\"Using custom GPT-2 TinyStories model  ({args.input_module}).\")\n",
            "        \n",
            "        from jiant.pytorch_transformers_interface.modules import GPT2EmbedderModule\n",
            "        embedder = GPT2EmbedderModule(args)\n",
            "        d_emb = embedder.get_output_dim()\n",
            "\t\n",
            "    else:\n",
            "        # Default case, used for ELMo, CoVe, word embeddings, etc.\n",
            "        d_emb, embedder, cove_layer = build_embeddings(args, vocab, tasks, pretrained_embs)\n",
            "\n",
            "    sent_encoder, d_sent_output = build_sent_encoder(\n",
            "        args, vocab, d_emb, tasks, embedder, cove_layer\n",
            "    )\n",
            "    # d_task_input is the input dimension of the task-specific module\n",
            "    # set skip_emb = 1 if you want to concatenate the encoder input with encoder output to pass\n",
            "    # into task specific module.\n",
            "    d_task_input = d_sent_output + (args.skip_embs * d_emb)\n",
            "\n",
            "    # Build model and classifiers\n",
            "    model = MultiTaskModel(args, sent_encoder, vocab)\n",
            "    build_task_modules(args, tasks, model, d_task_input, d_emb, embedder, vocab)\n",
            "    model = model.cuda() if args.cuda >= 0 else model\n",
            "    log.info(\"Model specification:\")\n",
            "    log.info(model)\n",
            "    param_count = 0\n",
            "    trainable_param_count = 0\n",
            "    if args.list_params:\n",
            "        log.info(\"Model parameters:\")\n",
            "    for name, param in model.named_parameters():\n",
            "        param_count += np.prod(param.size())\n",
            "        if param.requires_grad:\n",
            "            trainable_param_count += np.prod(param.size())\n",
            "            if args.list_params:\n",
            "                log.info(\n",
            "                    \"\\t%s: Trainable parameter, count %d with %s\",\n",
            "                    name,\n",
            "                    np.prod(param.size()),\n",
            "                    str(param.size()),\n",
            "                )\n",
            "        elif args.list_params:\n",
            "            log.info(\n",
            "                \"\\t%s: Non-trainable parameter, count %d with %s\",\n",
            "                name,\n",
            "                np.prod(param.size()),\n",
            "                str(param.size()),\n",
            "            )\n",
            "    log.info(\"Total number of parameters: {ct:d} ({ct:g})\".format(ct=param_count))\n",
            "    log.info(\"Number of trainable parameters: {ct:d} ({ct:g})\".format(ct=trainable_param_count))\n",
            "    return model\n",
            "\n",
            "\n",
            "def build_embeddings(args, vocab, tasks, pretrained_embs=None):\n",
            "    \"\"\" Build embeddings according to options in args \"\"\"\n",
            "    d_emb, d_char = 0, args.d_char\n",
            "\n",
            "    token_embedders = {}\n",
            "    # Word embeddings\n",
            "    n_token_vocab = vocab.get_vocab_size(\"tokens\")\n",
            "    if args.input_module in [\"glove\", \"fastText\"] and pretrained_embs is not None:\n",
            "        word_embs = pretrained_embs\n",
            "        assert word_embs.size()[0] == n_token_vocab\n",
            "        d_word = word_embs.size()[1]\n",
            "        log.info(\"\\tUsing pre-trained word embeddings: %s\", str(word_embs.size()))\n",
            "    elif args.input_module == \"scratch\":\n",
            "        log.info(\"\\tTraining word embeddings from scratch.\")\n",
            "        d_word = args.d_word\n",
            "        word_embs = nn.Embedding(n_token_vocab, d_word).weight\n",
            "    else:\n",
            "        assert input_module_uses_pytorch_transformers(args.input_module) or args.input_module in [\n",
            "            \"elmo\",\n",
            "            \"elmo-chars-only\",\n",
            "        ], f\"'{args.input_module}' is not a valid value for input_module.\"\n",
            "        embeddings = None\n",
            "        word_embs = None\n",
            "\n",
            "    if word_embs is not None:\n",
            "        embeddings = Embedding(\n",
            "            num_embeddings=n_token_vocab,\n",
            "            embedding_dim=d_word,\n",
            "            weight=word_embs,\n",
            "            trainable=(args.embeddings_train == 1),\n",
            "            padding_index=vocab.get_token_index(\"@@PADDING@@\"),\n",
            "        )\n",
            "        token_embedders[\"words\"] = embeddings\n",
            "        d_emb += d_word\n",
            "\n",
            "    # Handle cove\n",
            "    cove_layer = None\n",
            "    if args.cove:\n",
            "        assert embeddings is not None\n",
            "        assert args.input_module == \"glove\", \"CoVe requires GloVe embeddings.\"\n",
            "        assert d_word == 300, \"CoVe expects 300-dimensional GloVe embeddings.\"\n",
            "        try:\n",
            "            from jiant.modules.cove.cove import MTLSTM as cove_lstm\n",
            "\n",
            "            # Have CoVe do an internal GloVe lookup, but don't add residual.\n",
            "            # We'll do this manually in modules.py; see\n",
            "            # SentenceEncoder.forward().\n",
            "            cove_layer = cove_lstm(n_vocab=n_token_vocab, vectors=embeddings.weight.data)\n",
            "            # Control whether CoVe is trainable.\n",
            "            for param in cove_layer.parameters():\n",
            "                param.requires_grad = bool(args.cove_fine_tune)\n",
            "            d_emb += 600  # 300 x 2 for biLSTM activations\n",
            "            log.info(\"\\tUsing CoVe embeddings!\")\n",
            "        except ImportError as e:\n",
            "            log.info(\"Failed to import CoVe!\")\n",
            "            raise e\n",
            "\n",
            "    # Character embeddings\n",
            "    if args.char_embs:\n",
            "        log.info(\"\\tUsing character embeddings!\")\n",
            "        char_embeddings = Embedding(vocab.get_vocab_size(\"chars\"), d_char)\n",
            "        filter_sizes = tuple([int(i) for i in args.char_filter_sizes.split(\",\")])\n",
            "        char_encoder = CnnEncoder(\n",
            "            d_char,\n",
            "            num_filters=args.n_char_filters,\n",
            "            ngram_filter_sizes=filter_sizes,\n",
            "            output_dim=d_char,\n",
            "        )\n",
            "        char_embedder = TokenCharactersEncoder(\n",
            "            char_embeddings, char_encoder, dropout=args.dropout_embs\n",
            "        )\n",
            "        d_emb += d_char\n",
            "        token_embedders[\"chars\"] = char_embedder\n",
            "    else:\n",
            "        log.info(\"\\tNot using character embeddings!\")\n",
            "\n",
            "    # If we want separate ELMo scalar weights (a different ELMo representation for each classifier,\n",
            "    # then we need count and reliably map each classifier to an index used by\n",
            "    # allennlp internal ELMo.\n",
            "    if args.sep_embs_for_skip:\n",
            "        # Determine a deterministic list of classifier names to use for each\n",
            "        # task.\n",
            "        classifiers = sorted(set(map(lambda x: x._classifier_name, tasks)))\n",
            "        # Reload existing classifier map, if it exists.\n",
            "        classifier_save_path = args.run_dir + \"/classifier_task_map.json\"\n",
            "        if os.path.isfile(classifier_save_path):\n",
            "            loaded_classifiers = json.load(open(args.run_dir + \"/classifier_task_map.json\", \"r\"))\n",
            "        else:\n",
            "            # No file exists, so assuming we are just starting to pretrain. If pretrain is to be\n",
            "            # skipped, then there's a way to bypass this assertion by explicitly allowing for\n",
            "            # a missing classiifer task map.\n",
            "            assert_for_log(\n",
            "                args.do_pretrain or args.allow_missing_task_map,\n",
            "                \"Error: {} should already exist.\".format(classifier_save_path),\n",
            "            )\n",
            "            if args.allow_missing_task_map:\n",
            "                log.warning(\n",
            "                    \"Warning: classifier task map not found in model\"\n",
            "                    \" directory. Creating a new one from scratch.\"\n",
            "                )\n",
            "            # default is always @pretrain@\n",
            "            loaded_classifiers = {\"@pretrain@\": 0}\n",
            "        # Add the new tasks and update map, keeping the internal ELMo index\n",
            "        # consistent.\n",
            "        max_number_classifiers = max(loaded_classifiers.values())\n",
            "        offset = 1\n",
            "        for classifier in classifiers:\n",
            "            if classifier not in loaded_classifiers:\n",
            "                loaded_classifiers[classifier] = max_number_classifiers + offset\n",
            "                offset += 1\n",
            "        log.info(\"Classifiers:{}\".format(loaded_classifiers))\n",
            "        open(classifier_save_path, \"w+\").write(json.dumps(loaded_classifiers))\n",
            "        # Every index in classifiers needs to correspond to a valid ELMo output\n",
            "        # representation.\n",
            "        num_reps = 1 + max(loaded_classifiers.values())\n",
            "    else:\n",
            "        # All tasks share the same scalars.\n",
            "        # Not used if input_module = elmo-chars-only (i.e. no elmo)\n",
            "        loaded_classifiers = {\"@pretrain@\": 0}\n",
            "        num_reps = 1\n",
            "    if args.input_module.startswith(\"elmo\"):\n",
            "        log.info(\"Loading ELMo from files:\")\n",
            "        log.info(\"ELMO_OPT_PATH = %s\", ELMO_OPT_PATH)\n",
            "        if args.input_module == \"elmo-chars-only\":\n",
            "            log.info(\"\\tUsing ELMo character CNN only!\")\n",
            "            log.info(\"ELMO_WEIGHTS_PATH = %s\", ELMO_WEIGHTS_PATH)\n",
            "            elmo_embedder = ElmoCharacterEncoder(\n",
            "                options_file=ELMO_OPT_PATH, weight_file=ELMO_WEIGHTS_PATH, requires_grad=False\n",
            "            )\n",
            "            d_emb += 512\n",
            "        else:\n",
            "            log.info(\"\\tUsing full ELMo! (separate scalars/task)\")\n",
            "            if args.elmo_weight_file_path != \"none\":\n",
            "                assert os.path.exists(args.elmo_weight_file_path), (\n",
            "                    'ELMo weight file path \"' + args.elmo_weight_file_path + '\" does not exist.'\n",
            "                )\n",
            "                weight_file = args.elmo_weight_file_path\n",
            "            else:\n",
            "                weight_file = ELMO_WEIGHTS_PATH\n",
            "            log.info(\"ELMO_WEIGHTS_PATH = %s\", weight_file)\n",
            "            elmo_embedder = ElmoTokenEmbedderWrapper(\n",
            "                options_file=ELMO_OPT_PATH,\n",
            "                weight_file=weight_file,\n",
            "                num_output_representations=num_reps,\n",
            "                # Dropout is added by the sentence encoder later.\n",
            "                dropout=0.0,\n",
            "            )\n",
            "            d_emb += 1024\n",
            "\n",
            "        token_embedders[\"elmo\"] = elmo_embedder\n",
            "\n",
            "    # Wrap ELMo and other embedders, and concatenates the resulting\n",
            "    # representations alone the last (vector) dimension.\n",
            "    embedder = ElmoTextFieldEmbedder(\n",
            "        token_embedders,\n",
            "        loaded_classifiers,\n",
            "        elmo_chars_only=args.input_module == \"elmo-chars-only\",\n",
            "        sep_embs_for_skip=args.sep_embs_for_skip,\n",
            "    )\n",
            "\n",
            "    assert d_emb, \"You turned off all the embeddings, ya goof!\"\n",
            "    return d_emb, embedder, cove_layer\n",
            "\n",
            "\n",
            "def build_task_modules(args, tasks, model, d_sent, d_emb, embedder, vocab):\n",
            "    \"\"\"\n",
            "        This function gets the task-specific parameters and builds\n",
            "        the task-specific modules.\n",
            "    \"\"\"\n",
            "\n",
            "    # Attach task-specific params.\n",
            "    for task in set(tasks):\n",
            "        task_params = get_task_specific_params(args, task.name)\n",
            "        log.info(\n",
            "            \"\\tTask '%s' params: %s\",\n",
            "            task.name,\n",
            "            json.dumps(task_params.as_dict(quiet=True), indent=2),\n",
            "        )\n",
            "        # Store task-specific params in case we want to access later\n",
            "        setattr(model, \"%s_task_params\" % task.name, task_params)\n",
            "\n",
            "    # Actually construct modules.\n",
            "    for task in set(tasks):\n",
            "        # If the name of the task is different than the classifier it should use\n",
            "        # then skip the module creation.\n",
            "        if task.name != model._get_task_params(task.name).get(\"use_classifier\", task.name):\n",
            "            log.info(\"Name of the task is different than the classifier it should use\")\n",
            "            continue\n",
            "        build_task_specific_modules(task, model, d_sent, d_emb, vocab, embedder, args)\n",
            "\n",
            "\n",
            "def build_task_specific_modules(task, model, d_sent, d_emb, vocab, embedder, args):\n",
            "    \"\"\" Build task-specific components for a task and add them to model.\n",
            "        These include decoders, linear layers for linear models.\n",
            "    \"\"\"\n",
            "    task_params = model._get_task_params(task.name)\n",
            "    if isinstance(task, SingleClassificationTask):\n",
            "        module = build_single_sentence_module(\n",
            "            task=task,\n",
            "            d_inp=d_sent,\n",
            "            project_before_pooling=model.project_before_pooling,\n",
            "            params=task_params,\n",
            "        )\n",
            "        setattr(model, \"%s_mdl\" % task.name, module)\n",
            "    elif isinstance(task, (NPIClozePairTask, BlimpTask)):\n",
            "        hid2voc = model.sent_encoder._text_field_embedder.get_pretrained_lm_head()\n",
            "        setattr(model, \"%s_hid2voc\" % task.name, hid2voc)\n",
            "        model.file = open(\"%s_%s.jsonl\" % (args.exp_name, args.run_name), \"w\")\n",
            "    elif isinstance(task, (PairClassificationTask, PairRegressionTask, PairOrdinalRegressionTask)):\n",
            "        module = build_pair_sentence_module(task, d_sent, model=model, params=task_params)\n",
            "        setattr(model, \"%s_mdl\" % task.name, module)\n",
            "    elif isinstance(task, LanguageModelingParsingTask):\n",
            "        # The LM Parsing task does not support embeddings that use skip_embs.\n",
            "        hid2voc = build_lm(task, d_sent, args)\n",
            "        setattr(model, \"%s_hid2voc\" % task.name, hid2voc)\n",
            "        setattr(model, \"%s_mdl\" % task.name, hid2voc)\n",
            "    elif isinstance(task, LanguageModelingTask):\n",
            "        assert not input_module_uses_pytorch_transformers(args.input_module), (\n",
            "            \"our LM Task does not support pytorch_transformers, if you need them, try to update\",\n",
            "            \"corresponding parts of the code. You may find get_pretrained_lm_head and\",\n",
            "            \"apply_lm_boundary_tokens from pytorch_transformer_interface.module useful,\",\n",
            "            \"do check if they are working correctly though.\",\n",
            "        )\n",
            "        d_sent = args.d_hid + (args.skip_embs * d_emb)\n",
            "        hid2voc = build_lm(task, d_sent, args)\n",
            "        setattr(model, \"%s_hid2voc\" % task.name, hid2voc)\n",
            "    elif isinstance(task, SpanClassificationTask):\n",
            "        module = build_span_classifier(task, d_sent, task_params)\n",
            "        setattr(model, \"%s_mdl\" % task.name, module)\n",
            "    elif isinstance(task, TaggingTask):\n",
            "        hid2tag = build_tagger(task, d_sent, task.num_tags)\n",
            "        setattr(model, \"%s_mdl\" % task.name, hid2tag)\n",
            "    elif isinstance(task, MultipleChoiceTask):\n",
            "        module = build_multiple_choice_module(\n",
            "            task, d_sent, project_before_pooling=model.project_before_pooling, params=task_params\n",
            "        )\n",
            "        setattr(model, \"%s_mdl\" % task.name, module)\n",
            "    elif isinstance(task, EdgeProbingTask):\n",
            "        module = EdgeClassifierModule(task, d_sent, task_params)\n",
            "        setattr(model, \"%s_mdl\" % task.name, module)\n",
            "    elif isinstance(task, Seq2SeqTask):\n",
            "        log.info(\"using {} attention\".format(args.s2s[\"attention\"]))\n",
            "        decoder_params = Params(\n",
            "            {\n",
            "                \"input_dim\": d_sent,\n",
            "                \"target_embedding_dim\": 300,\n",
            "                \"decoder_hidden_size\": args.s2s[\"d_hid_dec\"],\n",
            "                \"output_proj_input_dim\": args.s2s[\"output_proj_input_dim\"],\n",
            "                \"max_decoding_steps\": args.max_seq_len,\n",
            "                \"target_namespace\": task._label_namespace\n",
            "                if hasattr(task, \"_label_namespace\")\n",
            "                else \"targets\",\n",
            "                \"attention\": args.s2s[\"attention\"],\n",
            "                \"dropout\": args.dropout,\n",
            "                \"scheduled_sampling_ratio\": 0.0,\n",
            "            }\n",
            "        )\n",
            "        decoder = Seq2SeqDecoder(vocab, **decoder_params)\n",
            "        setattr(model, \"%s_decoder\" % task.name, decoder)\n",
            "    elif isinstance(task, SequenceGenerationTask):\n",
            "        decoder, hid2voc = build_decoder(task, d_sent, vocab, embedder, args)\n",
            "        setattr(model, \"%s_decoder\" % task.name, decoder)\n",
            "        setattr(model, \"%s_hid2voc\" % task.name, hid2voc)\n",
            "    elif isinstance(task, (MultiRCTask, ReCoRDTask)):\n",
            "        module = build_qa_module(task, d_sent, model.project_before_pooling, task_params)\n",
            "        setattr(model, \"%s_mdl\" % task.name, module)\n",
            "    else:\n",
            "        raise ValueError(\"Module not found for %s\" % task.name)\n",
            "\n",
            "\n",
            "def get_task_specific_params(args, task_name):\n",
            "    \"\"\" Search args for parameters specific to task.\n",
            "    Args:\n",
            "        args: main-program args, a config.Params object\n",
            "        task_name: (string)\n",
            "    Returns:\n",
            "        AllenNLP Params object of task-specific params.\n",
            "    \"\"\"\n",
            "\n",
            "    def _get_task_attr(attr_name, default=None):\n",
            "        return config.get_task_attr(args, task_name, attr_name, default)\n",
            "\n",
            "    # This is confusing because a lot of parameters get renamed.\n",
            "    # TODO to replace with hierarchical configs and remove all the renaming and\n",
            "    # boilerplate.\n",
            "    params = {}\n",
            "    params[\"cls_type\"] = _get_task_attr(\"classifier\")\n",
            "    params[\"d_hid\"] = _get_task_attr(\"classifier_hid_dim\")\n",
            "    params[\"pool_type\"] = _get_task_attr(\"pool_type\")\n",
            "    params[\"d_proj\"] = _get_task_attr(\"d_proj\")\n",
            "    params[\"shared_pair_attn\"] = args.shared_pair_attn\n",
            "    if args.shared_pair_attn:\n",
            "        params[\"attn\"] = args.pair_attn\n",
            "        params[\"d_hid_attn\"] = args.d_hid_attn\n",
            "        params[\"dropout\"] = args.classifier_dropout\n",
            "    else:\n",
            "        params[\"attn\"] = _get_task_attr(\"pair_attn\")\n",
            "        params[\"d_hid_attn\"] = _get_task_attr(\"d_hid_attn\")\n",
            "        params[\"dropout\"] = _get_task_attr(\"classifier_dropout\")\n",
            "\n",
            "    # Used for span/edge classification. Other tasks can safely ignore.\n",
            "    params[\"cls_loss_fn\"] = _get_task_attr(\"span_classifier_loss_fn\")\n",
            "    params[\"cls_span_pooling\"] = _get_task_attr(\"classifier_span_pooling\")\n",
            "    params[\"edgeprobe_cnn_context\"] = _get_task_attr(\"edgeprobe_cnn_context\")\n",
            "    params[\"edgeprobe_symmetric\"] = _get_task_attr(\"edgeprobe_symmetric\")\n",
            "\n",
            "    # For NLI probing tasks, might want to use a classifier trained on\n",
            "    # something else (typically 'mnli').\n",
            "    cls_task_name = _get_task_attr(\"use_classifier\")\n",
            "    # default to this task\n",
            "    params[\"use_classifier\"] = cls_task_name or task_name\n",
            "\n",
            "    return Params(params)\n",
            "\n",
            "\n",
            "def build_image_sent_module(task, d_inp, params):\n",
            "    pooler = Pooler(project=True, d_inp=d_inp, d_proj=params[\"d_proj\"])\n",
            "    return pooler\n",
            "\n",
            "\n",
            "def build_single_sentence_module(task, d_inp: int, project_before_pooling: bool, params: Params):\n",
            "    \"\"\" Build a single sentence classifier\n",
            "\n",
            "    args:\n",
            "        - task (Task): task object, used to get the number of output classes\n",
            "        - d_inp (int): input dimension to the module, needed for optional linear projection\n",
            "        - project_before_pooling (bool): apply a projection layer before pooling.\n",
            "        - params (Params): Params object with task-specific parameters\n",
            "\n",
            "    returns:\n",
            "        - SingleClassifier (nn.Module): single-sentence classifier consisting of\n",
            "            (optional) a linear projection, pooling, and an MLP classifier\n",
            "    \"\"\"\n",
            "    pooler = Pooler(\n",
            "        project=project_before_pooling,\n",
            "        d_inp=d_inp,\n",
            "        d_proj=params[\"d_proj\"],\n",
            "        pool_type=params[\"pool_type\"],\n",
            "    )\n",
            "    d_out = params[\"d_proj\"] if project_before_pooling else d_inp\n",
            "    classifier = Classifier.from_params(d_out, task.n_classes, params)\n",
            "    module = SingleClassifier(pooler, classifier)\n",
            "    return module\n",
            "\n",
            "\n",
            "def build_pair_sentence_module(task, d_inp, model, params):\n",
            "    \"\"\" Build a pair classifier, shared if necessary \"\"\"\n",
            "\n",
            "    def build_pair_attn(d_in, d_hid_attn):\n",
            "        \"\"\" Build the pair model \"\"\"\n",
            "        d_inp_model = 2 * d_in\n",
            "        modeling_layer = s2s_e.by_name(\"lstm\").from_params(\n",
            "            Params(\n",
            "                {\n",
            "                    \"input_size\": d_inp_model,\n",
            "                    \"hidden_size\": d_hid_attn,\n",
            "                    \"num_layers\": 1,\n",
            "                    \"bidirectional\": True,\n",
            "                }\n",
            "            )\n",
            "        )\n",
            "        pair_attn = AttnPairEncoder(model.vocab, modeling_layer, dropout=params[\"dropout\"])\n",
            "        return pair_attn\n",
            "\n",
            "    # Build the \"pooler\", which does pools a variable length sequence\n",
            "    #   possibly with a projection layer beforehand\n",
            "    if params[\"attn\"] and model.project_before_pooling:\n",
            "        pooler = Pooler(project=False, d_inp=params[\"d_hid_attn\"], d_proj=params[\"d_hid_attn\"])\n",
            "        d_out = params[\"d_hid_attn\"] * 2\n",
            "    else:\n",
            "        pooler = Pooler(\n",
            "            project=model.project_before_pooling,\n",
            "            d_inp=d_inp,\n",
            "            d_proj=params[\"d_proj\"],\n",
            "            pool_type=params[\"pool_type\"],\n",
            "        )\n",
            "        d_out = params[\"d_proj\"] if model.project_before_pooling else d_inp\n",
            "\n",
            "    # Build an attention module if necessary\n",
            "    if params[\"shared_pair_attn\"] and params[\"attn\"]:  # shared attn\n",
            "        if not hasattr(model, \"pair_attn\"):\n",
            "            pair_attn = build_pair_attn(d_inp, params[\"d_hid_attn\"])\n",
            "            model.pair_attn = pair_attn\n",
            "        else:\n",
            "            pair_attn = model.pair_attn\n",
            "    elif params[\"attn\"]:  # non-shared attn\n",
            "        pair_attn = build_pair_attn(d_inp, params[\"d_hid_attn\"])\n",
            "    else:  # no attn\n",
            "        pair_attn = None\n",
            "\n",
            "    # Build the classifier\n",
            "    n_classes = task.n_classes if hasattr(task, \"n_classes\") else 1\n",
            "    if model.uses_pair_embedding:\n",
            "        # BERT/XLNet handle pair tasks by concatenating the inputs and classifying the joined\n",
            "        # sequence, so we use a single sentence classifier\n",
            "        if isinstance(task, WiCTask):\n",
            "            d_out *= 3  # also pass the two contextual word representations\n",
            "        classifier = Classifier.from_params(d_out, n_classes, params)\n",
            "        module = SingleClassifier(pooler, classifier)\n",
            "    else:\n",
            "        d_out = d_out + d_inp if isinstance(task, WiCTask) else d_out\n",
            "        classifier = Classifier.from_params(4 * d_out, n_classes, params)\n",
            "        module = PairClassifier(pooler, classifier, pair_attn)\n",
            "    return module\n",
            "\n",
            "\n",
            "def build_lm(task, d_inp, args):\n",
            "    \"\"\" Build LM components (just map hidden states to vocab logits) \"\"\"\n",
            "    hid2voc = nn.Linear(d_inp, args.max_word_v_size)\n",
            "    return hid2voc\n",
            "\n",
            "\n",
            "def build_span_classifier(task, d_sent, task_params):\n",
            "    module = SpanClassifierModule(task, d_sent, task_params, num_spans=task.num_spans)\n",
            "    return module\n",
            "\n",
            "\n",
            "def build_tagger(task, d_inp, out_dim):\n",
            "    \"\"\" Build tagger components. \"\"\"\n",
            "    hid2tag = nn.Linear(d_inp, out_dim)\n",
            "    return hid2tag\n",
            "\n",
            "\n",
            "def build_multiple_choice_module(task, d_sent, project_before_pooling, params):\n",
            "    \"\"\" Basic parts for MC task: reduce a vector representation for each model into a scalar. \"\"\"\n",
            "    pooler = Pooler(\n",
            "        project=project_before_pooling,\n",
            "        d_inp=d_sent,\n",
            "        d_proj=params[\"d_proj\"],\n",
            "        pool_type=params[\"pool_type\"],\n",
            "    )\n",
            "    d_out = params[\"d_proj\"] if project_before_pooling else d_sent\n",
            "    choice2scalar = Classifier(d_out, n_classes=1, cls_type=params[\"cls_type\"])\n",
            "    return SingleClassifier(pooler, choice2scalar)\n",
            "\n",
            "\n",
            "def build_decoder(task, d_inp, vocab, embedder, args):\n",
            "    \"\"\" Build a task specific decoder \"\"\"\n",
            "    rnn = s2s_e.by_name(\"lstm\").from_params(\n",
            "        Params(\n",
            "            {\n",
            "                \"input_size\": embedder.get_output_dim(),\n",
            "                \"hidden_size\": args.s2s[\"d_hid_dec\"],\n",
            "                \"num_layers\": args.s2s[\"n_layers_dec\"],\n",
            "                \"bidirectional\": False,\n",
            "            }\n",
            "        )\n",
            "    )\n",
            "    decoder = SentenceEncoder(vocab, embedder, 0, rnn)\n",
            "    hid2voc = nn.Linear(args.s2s[\"d_hid_dec\"], args.max_word_v_size)\n",
            "    return decoder, hid2voc\n",
            "\n",
            "\n",
            "def build_qa_module(task, d_inp, project_before_pooling, params):\n",
            "    \"\"\" Build a simple QA module that\n",
            "    1) pools representations (either of the joint (context, question, answer) or individually\n",
            "    2) projects down to two logits\n",
            "    3) classifier\n",
            "\n",
            "    This module models each question-answer pair _individually_ \"\"\"\n",
            "    pooler = Pooler(\n",
            "        project=project_before_pooling,\n",
            "        d_inp=d_inp,\n",
            "        d_proj=params[\"d_proj\"],\n",
            "        pool_type=params[\"pool_type\"],\n",
            "    )\n",
            "    d_out = params[\"d_proj\"] if project_before_pooling else d_inp\n",
            "    classifier = Classifier.from_params(d_out, 2, params)\n",
            "    return SingleClassifier(pooler, classifier)\n",
            "\n",
            "\n",
            "class MultiTaskModel(nn.Module):\n",
            "    \"\"\"\n",
            "    Giant model with task-specific components and a shared word and sentence encoder.\n",
            "    This class samples the tasks passed in pretrained_tasks, and adds task specific components\n",
            "    to the model.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, args, sent_encoder, vocab):\n",
            "        \"\"\" Args: sentence encoder \"\"\"\n",
            "        super(MultiTaskModel, self).__init__()\n",
            "        self.sent_encoder = sent_encoder\n",
            "        self.vocab = vocab\n",
            "        self.utilization = Average() if args.track_batch_utilization else None\n",
            "        self.elmo = args.input_module == \"elmo\"\n",
            "        self.uses_pair_embedding = input_module_uses_pair_embedding(args.input_module)\n",
            "        self.uses_mirrored_pair = input_module_uses_mirrored_pair(args.input_module)\n",
            "        self.project_before_pooling = not (\n",
            "            input_module_uses_pytorch_transformers(args.input_module)\n",
            "            and args.transfer_paradigm == \"finetune\"\n",
            "        )  # Rough heuristic. TODO: Make this directly user-controllable.\n",
            "        self.sep_embs_for_skip = args.sep_embs_for_skip\n",
            "\n",
            "    def forward(self, task, batch, predict=False):\n",
            "        \"\"\"\n",
            "        Pass inputs to correct forward pass\n",
            "        Args:\n",
            "            - task (tasks.Task): task for which batch is drawn\n",
            "            - batch (Dict[str:Dict[str:Tensor]]): dictionary of (field, indexing) pairs,\n",
            "                where indexing is a dict of the index namespace and the actual indices.\n",
            "            - predict (Bool): passed to task specific forward(). If true, forward()\n",
            "                should return predictions.\n",
            "        Returns:\n",
            "            - out: dictionary containing task outputs and loss if label was in batch\n",
            "        \"\"\"\n",
            "        if self.utilization is not None:\n",
            "            if \"input1\" in batch:\n",
            "                self.utilization(get_batch_utilization(batch[\"input1\"]))\n",
            "            elif \"input\" in batch:\n",
            "                self.utilization(get_batch_utilization(batch[\"input\"]))\n",
            "        if isinstance(task, SingleClassificationTask):\n",
            "            out = self._single_sentence_forward(batch, task, predict)\n",
            "        elif isinstance(task, GLUEDiagnosticTask):\n",
            "            out = self._nli_diagnostic_forward(batch, task, predict)\n",
            "        elif isinstance(task, (BlimpTask, NPIClozePairTask)):\n",
            "            out = self._minimal_pair_preference_forward(batch, task, predict)\n",
            "        elif isinstance(task, (NPIMinimalPairTask)):\n",
            "            out = self._minimal_pair_classification_forward(batch, task, predict)\n",
            "        elif isinstance(\n",
            "            task, (PairClassificationTask, PairRegressionTask, PairOrdinalRegressionTask)\n",
            "        ):\n",
            "            out = self._pair_sentence_forward(batch, task, predict)\n",
            "        elif isinstance(task, LanguageModelingTask):\n",
            "            if isinstance(self.sent_encoder._phrase_layer, ONLSTMStack) or isinstance(\n",
            "                self.sent_encoder._phrase_layer, PRPN\n",
            "            ):\n",
            "                out = self._lm_only_lr_forward(batch, task)\n",
            "            else:\n",
            "                out = self._lm_forward(batch, task, predict)\n",
            "        elif isinstance(task, TaggingTask):\n",
            "            out = self._tagger_forward(batch, task, predict)\n",
            "        elif isinstance(task, MultipleChoiceTask):\n",
            "            out = self._mc_forward(batch, task, predict)\n",
            "        elif isinstance(task, EdgeProbingTask):\n",
            "            # Just get embeddings and invoke task module.\n",
            "            word_embs_in_context, sent_mask = self.sent_encoder(batch[\"input1\"], task)\n",
            "            module = getattr(self, \"%s_mdl\" % task.name)\n",
            "            out = module.forward(batch, word_embs_in_context, sent_mask, task, predict)\n",
            "        elif isinstance(task, SequenceGenerationTask):\n",
            "            out = self._seq_gen_forward(batch, task, predict)\n",
            "        elif isinstance(task, (MultiRCTask, ReCoRDTask)):\n",
            "            out = self._multiple_choice_reading_comprehension_forward(batch, task, predict)\n",
            "        elif isinstance(task, SpanClassificationTask):\n",
            "            out = self._span_forward(batch, task, predict)\n",
            "        else:\n",
            "            raise ValueError(\"Task-specific components not found!\")\n",
            "        return out\n",
            "\n",
            "    def _get_task_params(self, task_name):\n",
            "        \"\"\" Get task-specific Params, as set in build_module(). \"\"\"\n",
            "        return getattr(self, \"%s_task_params\" % task_name)\n",
            "\n",
            "    def _get_classifier(self, task):\n",
            "        \"\"\" Get task-specific classifier, as set in build_module(). \"\"\"\n",
            "        # TODO: replace this logic with task._classifier_name?\n",
            "        task_params = self._get_task_params(task.name)\n",
            "        use_clf = task_params[\"use_classifier\"]\n",
            "        if use_clf in [None, \"\", \"none\"]:\n",
            "            use_clf = task.name  # default if not set\n",
            "        return getattr(self, \"%s_mdl\" % use_clf)\n",
            "\n",
            "    def _single_sentence_forward(self, batch, task, predict):\n",
            "        out = {}\n",
            "\n",
            "        # embed the sentence\n",
            "        word_embs_in_context, sent_mask = self.sent_encoder(batch[\"input1\"], task)\n",
            "        # pass to a task specific classifier\n",
            "        classifier = self._get_classifier(task)\n",
            "        logits = classifier(word_embs_in_context, sent_mask)\n",
            "        out[\"logits\"] = logits\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "\n",
            "        if \"labels\" in batch:  # means we should compute loss\n",
            "            if batch[\"labels\"].dim() == 0:\n",
            "                labels = batch[\"labels\"].unsqueeze(0)\n",
            "            elif batch[\"labels\"].dim() == 1:\n",
            "                labels = batch[\"labels\"]\n",
            "            else:\n",
            "                labels = batch[\"labels\"].squeeze(-1)\n",
            "            out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "            tagmask = batch.get(\"tagmask\", None)\n",
            "            task.update_metrics(logits, labels, tagmask=tagmask)\n",
            "\n",
            "        if predict:\n",
            "            if isinstance(task, RegressionTask):\n",
            "                if logits.ndimension() > 1:\n",
            "                    assert (\n",
            "                        logits.ndimension() == 2 and logits[-1] == 1\n",
            "                    ), \"Invalid regression prediction dimensions!\"\n",
            "                    logits = logits.squeeze(-1)\n",
            "                out[\"preds\"] = logits\n",
            "            else:\n",
            "                _, out[\"preds\"] = logits.max(dim=1)\n",
            "        return out\n",
            "\n",
            "    def _nli_diagnostic_forward(self, batch, task, predict):\n",
            "        out = {}\n",
            "\n",
            "        # embed the sentence\n",
            "        classifier = self._get_classifier(task)\n",
            "        if self.uses_pair_embedding:\n",
            "            sent, mask = self.sent_encoder(batch[\"inputs\"], task)\n",
            "            logits = classifier(sent, mask)\n",
            "        else:\n",
            "            sent1, mask1 = self.sent_encoder(batch[\"input1\"], task)\n",
            "            sent2, mask2 = self.sent_encoder(batch[\"input2\"], task)\n",
            "            logits = classifier(sent1, sent2, mask1, mask2)\n",
            "        out[\"logits\"] = logits\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "\n",
            "        if \"labels\" in batch:\n",
            "            if batch[\"labels\"].dim() == 0:\n",
            "                labels = batch[\"labels\"].unsqueeze(0)\n",
            "            elif batch[\"labels\"].dim() == 1:\n",
            "                labels = batch[\"labels\"]\n",
            "            else:\n",
            "                labels = batch[\"labels\"].squeeze(-1)\n",
            "            out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "            # task.update_diagnostic_metrics(predicted, labels, batch)\n",
            "            task.update_diagnostic_metrics(logits, labels, batch)\n",
            "\n",
            "        if predict:\n",
            "            _, predicted = logits.max(dim=1)\n",
            "            out[\"preds\"] = predicted\n",
            "\n",
            "        return out\n",
            "\n",
            "    def _span_forward(self, batch, task, predict):\n",
            "        sent_embs, sent_mask = self.sent_encoder(batch[\"input1\"], task)\n",
            "        module = getattr(self, \"%s_mdl\" % task.name)\n",
            "        out = module.forward(batch, sent_embs, sent_mask, task, predict)\n",
            "        return out\n",
            "\n",
            "    def _pair_sentence_forward(self, batch, task, predict):\n",
            "        out = {}\n",
            "\n",
            "        # embed the sentence\n",
            "        classifier = self._get_classifier(task)\n",
            "        if isinstance(task, (MRPCTask, STSBTask, QQPTask)) and self.uses_mirrored_pair:\n",
            "            # Mirrored pair is a trick used by GPT-like models in similarity tasks\n",
            "            # TODO: Wic also falls into this type, although GPT paper didn't expeirment with this task\n",
            "            sent, mask = self.sent_encoder(batch[\"inputs\"], task)\n",
            "            sent_m, mask_m = self.sent_encoder(batch[\"inputs_m\"], task)\n",
            "            logits = classifier(sent, mask) + classifier(sent_m, mask_m)\n",
            "        elif self.uses_pair_embedding:\n",
            "            sent, mask = self.sent_encoder(batch[\"inputs\"], task)\n",
            "            # special case for WiC b/c we want to add representations of particular tokens\n",
            "            if isinstance(task, WiCTask):\n",
            "                logits = classifier(sent, mask, [batch[\"idx1\"], batch[\"idx2\"]])\n",
            "            else:\n",
            "                logits = classifier(sent, mask)\n",
            "        else:\n",
            "            sent1, mask1 = self.sent_encoder(batch[\"input1\"], task)\n",
            "            sent2, mask2 = self.sent_encoder(batch[\"input2\"], task)\n",
            "            if isinstance(task, WiCTask):\n",
            "                logits = classifier(sent1, sent2, mask1, mask2, [batch[\"idx1\"]], [batch[\"idx2\"]])\n",
            "            else:\n",
            "                logits = classifier(sent1, sent2, mask1, mask2)\n",
            "        out[\"logits\"] = logits\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "        tagmask = batch.get(\"tagmask\", None)\n",
            "        if \"labels\" in batch:\n",
            "            labels = batch[\"labels\"]\n",
            "            labels = labels.squeeze(-1) if len(labels.size()) > 1 else labels\n",
            "            if isinstance(task, RegressionTask):\n",
            "                logits = logits.squeeze(-1) if len(logits.size()) > 1 else logits\n",
            "                out[\"loss\"] = F.mse_loss(logits, labels)\n",
            "                logits_np = logits.data.cpu().numpy()\n",
            "                labels_np = labels.data.cpu().numpy()\n",
            "                task.update_metrics(logits_np, labels_np, tagmask=tagmask)\n",
            "            else:\n",
            "                out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "                task.update_metrics(logits, labels, tagmask=tagmask)\n",
            "\n",
            "        if predict:\n",
            "            if isinstance(task, RegressionTask):\n",
            "                if logits.ndimension() > 1:\n",
            "                    assert (\n",
            "                        logits.ndimension() == 2 and logits[-1] == 1\n",
            "                    ), \"Invalid regression prediction dimensions!\"\n",
            "                    logits = logits.squeeze(-1)\n",
            "                out[\"preds\"] = logits\n",
            "            else:\n",
            "                _, out[\"preds\"] = logits.max(dim=1)\n",
            "        return out\n",
            "\n",
            "    def _minimal_pair_preference_forward(self, batch, task, predict):\n",
            "        out = {}\n",
            "\n",
            "        # embed the sentence\n",
            "        lm_head = getattr(self, \"%s_hid2voc\" % task.name)\n",
            "        tokenizer_name = list(batch[\"input1\"].keys())[0]\n",
            "        input1 = batch[\"input1\"][tokenizer_name]\n",
            "        input2 = batch[\"input2\"][tokenizer_name]\n",
            "        if isinstance(task, BlimpTask):\n",
            "            scale1 = torch.arange(\n",
            "                1, input1.size()[1], dtype=torch.long, device=input1.device\n",
            "            ).unsqueeze(0)\n",
            "            scale2 = torch.arange(\n",
            "                1, input2.size()[1], dtype=torch.long, device=input2.device\n",
            "            ).unsqueeze(0)\n",
            "            sent_embs1, sent_mask1 = self.sent_encoder(batch[\"input1\"], task)\n",
            "            sent_embs2, sent_mask2 = self.sent_encoder(batch[\"input2\"], task)\n",
            "            lm_pred1 = lm_head(sent_embs1[:, :-1, :])\n",
            "            lm_pred2 = lm_head(sent_embs2[:, :-1, :])\n",
            "            lm_logits1 = torch.gather(lm_pred1, dim=2, index=input1[:, 1:].unsqueeze(2)).squeeze(2)\n",
            "            lm_logits2 = torch.gather(lm_pred2, dim=2, index=input2[:, 1:].unsqueeze(2)).squeeze(2)\n",
            "            logit_mask1 = sent_mask1[:, 1:].squeeze(2)\n",
            "            logit_mask2 = sent_mask2[:, 1:].squeeze(2)\n",
            "        elif isinstance(task, NPIClozePairTask):\n",
            "            sent_embs0, sent_mask0 = self.sent_encoder(batch[\"input0\"], task)\n",
            "            sent_embs1, sent_mask1 = self.sent_encoder(batch[\"input1\"], task)\n",
            "            sent_embs2, sent_mask2 = self.sent_encoder(batch[\"input2\"], task)\n",
            "            lm_pred0 = lm_head(sent_embs0)\n",
            "            lm_logits1 = torch.gather(lm_pred0, dim=2, index=input1.unsqueeze(2)).squeeze(2)\n",
            "            lm_logits2 = torch.gather(lm_pred0, dim=2, index=input2.unsqueeze(2)).squeeze(2)\n",
            "            logit_mask1 = sent_mask1.squeeze(2)\n",
            "            logit_mask2 = sent_mask2.squeeze(2)\n",
            "        if isinstance(task, BlimpOnePrefixLMTask):\n",
            "            logit_mask1 = logit_mask1 * (\n",
            "                (scale1 >= batch[\"shared_prefix_length\"])\n",
            "                * (scale1 < batch[\"shared_prefix_length\"] + batch[\"good_word_length\"])\n",
            "            ).to(torch.float)\n",
            "            logit_mask2 = logit_mask2 * (\n",
            "                (scale2 >= batch[\"shared_prefix_length\"])\n",
            "                * (scale2 < batch[\"shared_prefix_length\"] + batch[\"bad_word_length\"])\n",
            "            ).to(torch.float)\n",
            "        elif isinstance(task, BlimpTwoPrefixLMTask):\n",
            "            logit_mask1 = logit_mask1 * (\n",
            "                (scale1 >= batch[\"good_prefix_length\"])\n",
            "                * (scale1 < batch[\"good_prefix_length\"] + batch[\"shared_word_length\"])\n",
            "            ).to(torch.float)\n",
            "            logit_mask2 = logit_mask2 * (\n",
            "                (scale2 >= batch[\"bad_prefix_length\"])\n",
            "                * (scale2 < batch[\"bad_prefix_length\"] + batch[\"shared_word_length\"])\n",
            "            ).to(torch.float)\n",
            "        elif isinstance(task, BlimpFullSentLMTask):\n",
            "            pass\n",
            "        elif isinstance(task, NPIClozePairTask):\n",
            "            logit_mask1 = logit_mask1 * (input1 != input2).to(torch.float)\n",
            "            logit_mask2 = logit_mask2 * (input1 != input2).to(torch.float)\n",
            "        pref_logits1 = torch.sum(lm_logits1 * logit_mask1, dim=1)\n",
            "        pref_logits2 = torch.sum(lm_logits2 * logit_mask2, dim=1)\n",
            "        logits = torch.stack([pref_logits1, pref_logits2], dim=1)\n",
            "\n",
            "        out[\"logits\"] = logits\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "        tagmask = batch.get(\"tagmask\", None)\n",
            "        if \"labels\" in batch:\n",
            "            labels = batch[\"labels\"]\n",
            "            labels = labels.squeeze(-1) if len(labels.size()) > 1 else labels\n",
            "            out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "            task.update_metrics(logits, labels, tagmask=tagmask)\n",
            "\n",
            "        if isinstance(task, BlimpFullSentLMTask):\n",
            "            for i in range(out[\"n_exs\"]):\n",
            "                output = {\n",
            "                    \"sent1_str\": batch[\"sent1_str\"][i],\n",
            "                    \"sent2_str\": batch[\"sent2_str\"][i],\n",
            "                    \"lm_prob1\": pref_logits1[i].tolist(),\n",
            "                    \"lm_prob2\": pref_logits2[i].tolist(),\n",
            "                    \"sent_mask1\": sent_mask1[:, 1:].squeeze(2)[i].tolist(),\n",
            "                    \"sent_mask2\": sent_mask2[:, 1:].squeeze(2)[i].tolist(),\n",
            "                    \"pairID\": batch[\"pairID\"][i],\n",
            "                    \"UID\": batch[\"UID\"][i],\n",
            "                }\n",
            "                self.file.write(json.dumps(output) + \"\\n\")\n",
            "        elif isinstance(task, BlimpOnePrefixLMTask):\n",
            "            entropy1 = -(torch.exp(lm_pred1) * lm_pred1).sum(dim=-1)\n",
            "            entropy2 = -(torch.exp(lm_pred2) * lm_pred2).sum(dim=-1)\n",
            "            appen_mask1 = sent_mask1[:, 1:].squeeze(2) * (\n",
            "                scale1 >= batch[\"shared_prefix_length\"] + batch[\"good_word_length\"]\n",
            "            ).to(torch.float)\n",
            "            appen_mask2 = sent_mask2[:, 1:].squeeze(2) * (\n",
            "                scale2 >= batch[\"shared_prefix_length\"] + batch[\"bad_word_length\"]\n",
            "            ).to(torch.float)\n",
            "            appen_entropy1 = (entropy1 * appen_mask1).sum(dim=1)\n",
            "            appen_entropy2 = (entropy2 * appen_mask2).sum(dim=1)\n",
            "            appen_logits1 = torch.sum(lm_logits1 * appen_mask1, dim=1)\n",
            "            appen_logits2 = torch.sum(lm_logits2 * appen_mask2, dim=1)\n",
            "            for i in range(out[\"n_exs\"]):\n",
            "                output = {\n",
            "                    \"sent1_str\": batch[\"sent1_str\"][i],\n",
            "                    \"sent2_str\": batch[\"sent2_str\"][i],\n",
            "                    \"appen_entropy1\": appen_entropy1[i].tolist(),\n",
            "                    \"appen_entropy2\": appen_entropy2[i].tolist(),\n",
            "                    \"crit_logits1\": pref_logits1[i].tolist(),\n",
            "                    \"crit_logits2\": pref_logits2[i].tolist(),\n",
            "                    \"appen_logits1\": appen_logits1[i].tolist(),\n",
            "                    \"appen_logits2\": appen_logits2[i].tolist(),\n",
            "                    \"pairID\": batch[\"pairID\"][i],\n",
            "                    \"UID\": batch[\"UID\"][i],\n",
            "                }\n",
            "                self.file.write(json.dumps(output) + \"\\n\")\n",
            "        elif isinstance(task, BlimpTwoPrefixLMTask):\n",
            "            entropy1 = -(torch.exp(lm_pred1) * lm_pred1).sum(dim=-1)\n",
            "            entropy2 = -(torch.exp(lm_pred2) * lm_pred2).sum(dim=-1)\n",
            "            appen_mask1 = sent_mask1[:, 1:].squeeze(2) * (\n",
            "                scale1 >= batch[\"good_prefix_length\"] + batch[\"shared_word_length\"]\n",
            "            ).to(torch.float)\n",
            "            appen_mask2 = sent_mask2[:, 1:].squeeze(2) * (\n",
            "                scale2 >= batch[\"bad_prefix_length\"] + batch[\"shared_word_length\"]\n",
            "            ).to(torch.float)\n",
            "            prefix_mask1 = sent_mask1[:, 1:].squeeze(2) * (scale1 < batch[\"good_prefix_length\"]).to(\n",
            "                torch.float\n",
            "            )\n",
            "            prefix_mask2 = sent_mask2[:, 1:].squeeze(2) * (scale2 < batch[\"bad_prefix_length\"]).to(\n",
            "                torch.float\n",
            "            )\n",
            "            appen_entropy1 = (entropy1 * appen_mask1).sum(dim=1)\n",
            "            appen_entropy2 = (entropy2 * appen_mask2).sum(dim=1)\n",
            "            appen_logits1 = torch.sum(lm_logits1 * appen_mask1, dim=1)\n",
            "            appen_logits2 = torch.sum(lm_logits2 * appen_mask2, dim=1)\n",
            "            prefix_logits1 = torch.sum(lm_logits1 * prefix_mask1, dim=1)\n",
            "            prefix_logits2 = torch.sum(lm_logits2 * prefix_mask2, dim=1)\n",
            "            for i in range(out[\"n_exs\"]):\n",
            "                output = {\n",
            "                    \"sent1_str\": batch[\"sent1_str\"][i],\n",
            "                    \"sent2_str\": batch[\"sent2_str\"][i],\n",
            "                    \"appen_entropy1\": appen_entropy1[i].tolist(),\n",
            "                    \"appen_entropy2\": appen_entropy2[i].tolist(),\n",
            "                    \"crit_logits1\": pref_logits1[i].tolist(),\n",
            "                    \"crit_logits2\": pref_logits2[i].tolist(),\n",
            "                    \"appen_logits1\": appen_logits1[i].tolist(),\n",
            "                    \"appen_logits2\": appen_logits2[i].tolist(),\n",
            "                    \"pref_logits1\": prefix_logits1[i].tolist(),\n",
            "                    \"pref_logits2\": prefix_logits2[i].tolist(),\n",
            "                    \"pairID\": batch[\"pairID\"][i],\n",
            "                    \"UID\": batch[\"UID\"][i],\n",
            "                }\n",
            "                self.file.write(json.dumps(output) + \"\\n\")\n",
            "\n",
            "        if predict:\n",
            "            _, out[\"preds\"] = logits.max(dim=1)\n",
            "        return out\n",
            "\n",
            "    def _minimal_pair_classification_forward(self, batch, task, predict):\n",
            "        \"\"\"\n",
            "        run acceptablity judgement task on minimal pairs\n",
            "        \"\"\"\n",
            "        out = {}\n",
            "\n",
            "        # embed the sentence\n",
            "        sent_embs1, sent_mask1 = self.sent_encoder(batch[\"input1\"], task)\n",
            "        sent_embs2, sent_mask2 = self.sent_encoder(batch[\"input2\"], task)\n",
            "        # pass to a task specific classifier\n",
            "        classifier = self._get_classifier(task)\n",
            "        logits1 = classifier(sent_embs1, sent_mask1)\n",
            "        logits2 = classifier(sent_embs2, sent_mask2)\n",
            "        logits = torch.stack(\n",
            "            (\n",
            "                logits1[:, 1] + logits2[:, 0],\n",
            "                logits1[:, 0] + logits2[:, 1],\n",
            "                logits1[:, 1] + logits2[:, 1],\n",
            "                logits1[:, 0] + logits2[:, 0],\n",
            "            ),\n",
            "            dim=1,\n",
            "        )\n",
            "\n",
            "        out[\"logits\"] = logits\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "        tagmask = batch.get(\"tagmask\", None)\n",
            "        if \"labels\" in batch:\n",
            "            labels = batch[\"labels\"]\n",
            "            labels = labels.squeeze(-1) if len(labels.size()) > 1 else labels\n",
            "            out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "            task.update_metrics(logits, labels, tagmask=tagmask)\n",
            "\n",
            "        if predict:\n",
            "            _, out[\"preds\"] = logits.max(dim=1)\n",
            "        return out\n",
            "\n",
            "    def _seq_gen_forward(self, batch, task, predict):\n",
            "        \"\"\" For sequence generation tasks \"\"\"\n",
            "        out = {}\n",
            "        sent, sent_mask = self.sent_encoder(batch[\"inputs\"], task)\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "\n",
            "        decoder = getattr(self, \"%s_decoder\" % task.name)\n",
            "        out.update(decoder.forward(sent, sent_mask, batch[\"targs\"]))\n",
            "        task.scorer1(out[\"loss\"].item())\n",
            "\n",
            "        if \"targs\" in batch:\n",
            "            # logits: batch_size * seq_len * tgt_voc_size\n",
            "            target = batch[\"targs\"][\"words\"][:, 1:].contiguous()\n",
            "            target_mask = out[\"target_mask\"]\n",
            "            logits = out[\"logits\"]\n",
            "            task.update_metrics(logits, target, target_mask[:, 1:].contiguous())\n",
            "\n",
            "        if predict:\n",
            "            pass\n",
            "\n",
            "        return out\n",
            "\n",
            "    def _tagger_forward(self, batch: dict, task: TaggingTask, predict: bool) -> dict:\n",
            "        \"\"\"\n",
            "        This function is for sequence tagging (one-to-one mapping between words and tags).\n",
            "        Args:\n",
            "                batch: a dict of inputs and target tags\n",
            "                task: TaggingTask\n",
            "                predict: (boolean) predict mode (not supported)\n",
            "        Returns\n",
            "            out: (dict)\n",
            "                - 'logits': output layer, dimension: [batchSize * task.max_seq_len, task.num_tags]\n",
            "                - 'loss': size average CE loss\n",
            "        \"\"\"\n",
            "        out = {}\n",
            "        # batch[inputs] only has one item\n",
            "        b_size, seq_len = list(batch[\"inputs\"].values())[0].size()\n",
            "        seq_len -= 2\n",
            "        sent_encoder = self.sent_encoder\n",
            "        out[\"n_exs\"] = get_batch_size(batch)\n",
            "        if not isinstance(sent_encoder, BiLMEncoder):\n",
            "            sent, mask = sent_encoder(batch[\"inputs\"], task)\n",
            "            sent = sent.masked_fill(1 - mask.byte(), 0)  # avoid NaNs\n",
            "            sent = sent[:, 1:-1, :]\n",
            "            hid2tag = self._get_classifier(task)\n",
            "            logits = hid2tag(sent)\n",
            "            logits = logits.view(b_size * seq_len, -1)\n",
            "            out[\"logits\"] = logits\n",
            "            targs = batch[\"targs\"][\"words\"][:, :seq_len].contiguous().view(-1)\n",
            "        if \"mask\" in batch:\n",
            "            # prevent backprop for tags generated for tokenization-introduced tokens\n",
            "            # such as word boundaries\n",
            "            mask = batch[\"mask\"]\n",
            "            batch_mask = [mask[i][:seq_len] for i in range(b_size)]\n",
            "            batch_mask = torch.stack(batch_mask)\n",
            "            keep_idxs = torch.nonzero(batch_mask.view(-1).data).squeeze()\n",
            "            logits = logits.index_select(0, keep_idxs)\n",
            "            targs = targs.index_select(0, keep_idxs)\n",
            "        pad_idx = self.vocab.get_token_index(self.vocab._padding_token)\n",
            "        out[\"loss\"] = F.cross_entropy(logits, targs, ignore_index=pad_idx)\n",
            "        task.scorer1(logits, targs)\n",
            "        return out\n",
            "\n",
            "    def _lm_forward(self, batch, task, predict):\n",
            "        \"\"\"Forward pass for LM model\n",
            "        Args:\n",
            "            batch: indexed input data\n",
            "            task: (Task obejct)\n",
            "            predict: (boolean) predict mode (not supported)\n",
            "        return:\n",
            "            out: (dict)\n",
            "                - 'logits': output layer, dimension: [batchSize * timeSteps * 2, outputDim]\n",
            "                            first half: [:batchSize*timeSteps, outputDim] is output layer from\n",
            "                                forward layer\n",
            "                            second half: [batchSize*timeSteps:, outputDim] is output layer from\n",
            "                                backward layer\n",
            "                - 'loss': size average CE loss\n",
            "        \"\"\"\n",
            "        out = {}\n",
            "        sent_encoder = self.sent_encoder\n",
            "        assert_for_log(\n",
            "            isinstance(sent_encoder._phrase_layer, BiLMEncoder),\n",
            "            \"Not using LM for language modeling task!\",\n",
            "        )\n",
            "        assert_for_log(\n",
            "            \"targs\" in batch and \"words\" in batch[\"targs\"], \"Batch missing target words!\"\n",
            "        )\n",
            "        pad_idx = self.vocab.get_token_index(self.vocab._padding_token, \"tokens\")\n",
            "        b_size, seq_len = batch[\"targs\"][\"words\"].size()\n",
            "        n_pad = batch[\"targs\"][\"words\"].eq(pad_idx).sum().item()\n",
            "        out[\"n_exs\"] = (b_size * seq_len - n_pad) * 2\n",
            "\n",
            "        sent, mask = sent_encoder(batch[\"input\"], task)\n",
            "        sent = sent.masked_fill(1 - mask.byte(), 0)  # avoid NaNs\n",
            "\n",
            "        # Split encoder outputs by direction\n",
            "        split = int(self.sent_encoder._phrase_layer.get_output_dim() / 2)\n",
            "        fwd, bwd = sent[:, :, :split], sent[:, :, split : split * 2]\n",
            "        if split * 2 < sent.size(2):  # skip embeddings\n",
            "            out_embs = sent[:, :, split * 2 :]\n",
            "            fwd = torch.cat([fwd, out_embs], dim=2)\n",
            "            bwd = torch.cat([bwd, out_embs], dim=2)\n",
            "\n",
            "        # Forward and backward logits and targs\n",
            "        hid2voc = getattr(self, \"%s_hid2voc\" % task.name)\n",
            "        logits_fwd = hid2voc(fwd).view(b_size * seq_len, -1)\n",
            "        logits_bwd = hid2voc(bwd).view(b_size * seq_len, -1)\n",
            "        logits = torch.cat([logits_fwd, logits_bwd], dim=0)\n",
            "        out[\"logits\"] = logits\n",
            "        trg_fwd = batch[\"targs\"][\"words\"].view(-1)\n",
            "        trg_bwd = batch[\"targs_b\"][\"words\"].view(-1)\n",
            "        targs = torch.cat([trg_fwd, trg_bwd], dim=0)\n",
            "        assert logits.size(0) == targs.size(0), \"Number of logits and targets differ!\"\n",
            "        out[\"loss\"] = F.cross_entropy(logits, targs, ignore_index=pad_idx)\n",
            "        task.scorer1(out[\"loss\"].item())\n",
            "        if predict:\n",
            "            pass\n",
            "        return out\n",
            "\n",
            "    def _mc_forward(self, batch, task, predict):\n",
            "        \"\"\" Forward for a multiple choice question answering task \"\"\"\n",
            "        out = {}\n",
            "\n",
            "        logits = []\n",
            "        module = self._get_classifier(task)\n",
            "        if self.uses_pair_embedding:\n",
            "            for choice_idx in range(task.n_choices):\n",
            "                sent, mask = self.sent_encoder(batch[\"choice%d\" % choice_idx], task)\n",
            "                logit = module(sent, mask)\n",
            "                logits.append(logit)\n",
            "        else:\n",
            "            ctx, ctx_mask = self.sent_encoder(batch[\"question\"], task)\n",
            "            for choice_idx in range(task.n_choices):\n",
            "                sent, mask = self.sent_encoder(batch[\"choice%d\" % choice_idx], task)\n",
            "                inp = torch.cat([ctx, sent], dim=1)\n",
            "                inp_mask = torch.cat([ctx_mask, mask], dim=1)\n",
            "                logit = module(inp, inp_mask)\n",
            "                logits.append(logit)\n",
            "        logits = torch.cat(logits, dim=1)\n",
            "        out[\"logits\"] = logits\n",
            "        out[\"n_exs\"] = get_batch_size(batch, keyword=\"choice0\")\n",
            "\n",
            "        if \"label\" in batch:\n",
            "            labels = batch[\"label\"]\n",
            "            out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "            task.update_metrics(logits, labels)\n",
            "\n",
            "        if predict:\n",
            "            out[\"preds\"] = logits.argmax(dim=-1)\n",
            "\n",
            "        return out\n",
            "\n",
            "    def _lm_only_lr_forward(self, batch, task):\n",
            "        \"\"\"Only left to right pass for LM model - non-bidirectional models.\n",
            "           Used for language modeling training only in one direction.\n",
            "        Args:\n",
            "            batch: indexed input data\n",
            "            task: (Task obejct)\n",
            "        return:\n",
            "            out: (dict)\n",
            "                - 'logits': output layer, dimension: [batchSize * timeSteps, outputDim]\n",
            "                    is output layer from forward layer\n",
            "                - 'loss': size average CE loss\n",
            "        \"\"\"\n",
            "\n",
            "        out = {}\n",
            "        assert_for_log(\n",
            "            \"targs\" in batch and \"words\" in batch[\"targs\"], \"Batch missing target words!\"\n",
            "        )\n",
            "        pad_idx = self.vocab.get_token_index(self.vocab._padding_token, \"tokens\")\n",
            "        b_size, seq_len = batch[\"targs\"][\"words\"].size()\n",
            "        # pad_idx is the token used to pad till max_seq_len\n",
            "        n_pad = batch[\"targs\"][\"words\"].eq(pad_idx).sum().item()\n",
            "        # No of examples: only left to right, every unit in the sequence length is\n",
            "        # a training example only once.\n",
            "        out[\"n_exs\"] = b_size * seq_len - n_pad\n",
            "        sent, mask = self.sent_encoder(batch[\"input\"], task)\n",
            "        sent = sent.masked_fill(1 - mask.byte(), 0)\n",
            "        hid2voc = getattr(self, \"%s_hid2voc\" % task.name)\n",
            "        logits = hid2voc(sent).view(b_size * seq_len, -1)\n",
            "        out[\"logits\"] = logits\n",
            "        trg_fwd = batch[\"targs\"][\"words\"].view(-1)\n",
            "        assert logits.size(0) == trg_fwd.size(0), \"Number of logits and targets differ!\"\n",
            "        out[\"loss\"] = F.cross_entropy(logits, trg_fwd, ignore_index=pad_idx)\n",
            "        task.scorer1(out[\"loss\"].item())\n",
            "        return out\n",
            "\n",
            "    def _multiple_choice_reading_comprehension_forward(self, batch, task, predict):\n",
            "        \"\"\" Forward call for multiple choice (selecting from a fixed set of answers)\n",
            "        reading comprehension (have a supporting paragraph).\n",
            "\n",
            "        Batch has a tensor of shape (n_questions, n_answers, n_tokens)\n",
            "        \"\"\"\n",
            "        out = {}\n",
            "        classifier = self._get_classifier(task)\n",
            "        if self.uses_pair_embedding:\n",
            "            # if using BERT/XLNet, we concatenate the passage, question, and answer\n",
            "            inp = batch[\"psg_qst_ans\"]\n",
            "            ex_embs, ex_mask = self.sent_encoder(inp, task)\n",
            "            logits = classifier(ex_embs, ex_mask)\n",
            "            out[\"n_exs\"] = get_batch_size(batch, keyword=\"psg_qst_ans\")\n",
            "        else:\n",
            "            # else, we embed each independently and concat them\n",
            "            psg_emb, psg_mask = self.sent_encoder(batch[\"psg\"], task)\n",
            "            qst_emb, qst_mask = self.sent_encoder(batch[\"qst\"], task)\n",
            "\n",
            "            if \"ans\" in batch:  # most QA tasks, e.g. MultiRC have explicit answer fields\n",
            "                ans_emb, ans_mask = self.sent_encoder(batch[\"ans\"], task)\n",
            "                inp = torch.cat([psg_emb, qst_emb, ans_emb], dim=1)\n",
            "                inp_mask = torch.cat([psg_mask, qst_mask, ans_mask], dim=1)\n",
            "                out[\"n_exs\"] = get_batch_size(batch, keyword=\"ans\")\n",
            "            else:  # ReCoRD inserts answer into the query\n",
            "                inp = torch.cat([psg_emb, qst_emb], dim=1)\n",
            "                inp_mask = torch.cat([psg_mask, qst_mask], dim=1)\n",
            "                out[\"n_exs\"] = get_batch_size(batch, keyword=\"qst\")\n",
            "\n",
            "            logits = classifier(inp, inp_mask)\n",
            "        out[\"logits\"] = logits\n",
            "\n",
            "        if \"label\" in batch:\n",
            "            idxs = [(p, q) for p, q in zip(batch[\"psg_idx\"], batch[\"qst_idx\"])]\n",
            "            labels = batch[\"label\"]\n",
            "            out[\"loss\"] = F.cross_entropy(logits, labels)\n",
            "            if isinstance(task, ReCoRDTask):\n",
            "                # ReCoRD needs the answer string to compute F1\n",
            "                task.update_metrics(logits, batch[\"ans_str\"], idxs)\n",
            "            else:\n",
            "                task.update_metrics(logits, labels, idxs)\n",
            "\n",
            "        if predict:\n",
            "            if isinstance(task, ReCoRDTask):\n",
            "                # for ReCoRD, we want the logits to make\n",
            "                # predictions across answer choices\n",
            "                # (which are spread across batches)\n",
            "                out[\"preds\"] = logits\n",
            "            else:\n",
            "                out[\"preds\"] = logits.argmax(dim=-1)\n",
            "\n",
            "        return out\n",
            "\n",
            "    def get_elmo_mixing_weights(self, tasks=[]):\n",
            "        \"\"\" Get elmo mixing weights from text_field_embedder. Gives warning when fails.\n",
            "        args:\n",
            "           - tasks (List[Task]): list of tasks that we want to get  ELMo scalars for.\n",
            "        returns:\n",
            "            - params Dict[str:float]: dictionary maybe layers to scalar params\n",
            "        \"\"\"\n",
            "        params = {}\n",
            "        if self.elmo:\n",
            "            if not self.sep_embs_for_skip:\n",
            "                tasks = [None]\n",
            "            else:\n",
            "                tasks = [None] + tasks\n",
            "            for task in tasks:\n",
            "                if task:\n",
            "                    params[task._classifier_name] = get_elmo_mixing_weights(\n",
            "                        self.sent_encoder._text_field_embedder, task=task\n",
            "                    )\n",
            "                else:\n",
            "                    params[\"@pretrain@\"] = get_elmo_mixing_weights(\n",
            "                        self.sent_encoder._text_field_embedder, task=None\n",
            "                    )\n",
            "        return params\n",
            "\n",
            "\n",
            "def input_module_uses_pair_embedding(input_module):\n",
            "    \"\"\"\n",
            "    This function tells whether the input module concatenate the two sentences in a pair when\n",
            "    running on pair tasks, like what GPT / BERT do on MNLI.\n",
            "    It seems redundant now, but it allows us to load similar models from other sources later on\n",
            "    \"\"\"\n",
            "    from jiant.pytorch_transformers_interface import input_module_uses_pytorch_transformers\n",
            "\n",
            "    return input_module_uses_pytorch_transformers(input_module)\n",
            "\n",
            "\n",
            "def input_module_uses_mirrored_pair(input_module):\n",
            "    \"\"\"\n",
            "    This function tells whether the input model uses raw pair and mirrored pair simutaneously when\n",
            "    running on symmetrical pair tasks, like what GPT do on STS-B \n",
            "    \"\"\"\n",
            "    return (\n",
            "        input_module.startswith(\"openai-gpt\")\n",
            "        or input_module.startswith(\"gpt2\")\n",
            "        or input_module.startswith(\"transfo-xl-\")\n",
            "    )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./tiny_gpt2_tiny_stories/checkpoint-500"
      ],
      "metadata": {
        "id": "OcgAMlZk5Y54",
        "outputId": "adfe5de1-543d-4f80-c366-e03410a1d74d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t\tmodel.safetensors  rng_state.pth  trainer_state.json\n",
            "generation_config.json\toptimizer.pt\t   scheduler.pt   training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhKW03or7BFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}