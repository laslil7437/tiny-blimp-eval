// Run languistic phenomena benchmark over pretrained GPT2 medium.
include "../defaults.conf"  // relative path to this file

exp_name = "blimp-gpt2"
run_name = "run"  // default

pretrain_tasks = ""  // empty: don't run main training phase
target_tasks = "blimp-oneprefix,blimp-twoprefix,blimp-simpleLM"   // train classifier only

// Eval will use task-specific params.
do_pretrain = 0        // skip main train phase
allow_untrained_encoder_parameters = 1  // allow skipping training phase
allow_missing_task_map = 1  // ignore missing classifier_task_map.json
do_target_task_training = 0  // train using eval task params
do_full_eval = 1
write_preds = "val"

input_module = "gpt2-large"

// Use no-op encoder (no params).
skip_embs = 1  // forward embeddings from lower level.
sep_embs_for_skip = 1
sent_enc = "none"